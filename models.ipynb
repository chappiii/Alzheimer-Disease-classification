{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee76958b-883c-4995-bdd4-34842de8464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "746d9360-11ac-4465-9ba4-35bd6a294788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2149, 35)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "data = pd.read_csv(\"alzheimers_disease_data.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9557af2e-d86e-4ddc-b724-e3b921a77aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['PatientID', 'DoctorInCharge'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c2fb431-e236-4044-94f3-adaaf69a9c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2149, 33)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef63cc35-e5ac-45ae-8a2a-4e4049d4ba90",
   "metadata": {},
   "source": [
    "### under sampling balance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1360418-ec8f-4993-a441-1f24b43c5670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class Distribution:\n",
      " Diagnosis\n",
      "0    64.634714\n",
      "1    35.365286\n",
      "Name: proportion, dtype: float64\n",
      "Balanced Class Distribution:\n",
      " Diagnosis\n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "class_counts = data.iloc[:, -1].value_counts(normalize=True) * 100\n",
    "print(\"Original Class Distribution:\\n\", class_counts)\n",
    "\n",
    "# Splitting features and target variable\n",
    "X = data.iloc[:, :-1]  # Features\n",
    "y = data.iloc[:, -1]   # Target\n",
    "\n",
    "# Separate majority and minority classes\n",
    "majority_class = data[y == 0]  # Non-Alzheimer's (64.6%)\n",
    "minority_class = data[y == 1]  # Alzheimer's (35.4%)\n",
    "\n",
    "# Undersample the majority class to match the minority class size\n",
    "majority_downsampled = resample(majority_class, \n",
    "                                replace=False,  # Without replacement\n",
    "                                n_samples=len(minority_class),  # Match minority class size\n",
    "                                random_state=42)\n",
    "\n",
    "# Combine the downsampled majority class with the original minority class\n",
    "balanced_data = pd.concat([majority_downsampled, minority_class])\n",
    "\n",
    "# Shuffle the dataset\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check new class distribution\n",
    "new_class_counts = balanced_data.iloc[:, -1].value_counts(normalize=True) * 100\n",
    "print(\"Balanced Class Distribution:\\n\", new_class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be64a91b-4753-4b78-bac2-54e499756d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1520, 33)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574607ef-7ad8-4b5a-9a36-b9a3499527b4",
   "metadata": {},
   "source": [
    "### over sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19a19c88-cf96-4af0-b385-724813dec919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class Distribution:\n",
      " Diagnosis\n",
      "0    64.634714\n",
      "1    35.365286\n",
      "Name: proportion, dtype: float64\n",
      "Balanced Class Distribution:\n",
      " Diagnosis\n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "class_counts = data.iloc[:, -1].value_counts(normalize=True) * 100\n",
    "print(\"Original Class Distribution:\\n\", class_counts)\n",
    "\n",
    "# Splitting features and target variable\n",
    "X = data.iloc[:, :-1]  # Features\n",
    "y = data.iloc[:, -1]   # Target\n",
    "\n",
    "# Apply SMOTE for oversampling the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Create a new balanced DataFrame\n",
    "balanced_data = pd.concat([pd.DataFrame(X_resampled), pd.DataFrame(y_resampled, columns=[y.name])], axis=1)\n",
    "\n",
    "# Check new class distribution\n",
    "new_class_counts = balanced_data.iloc[:, -1].value_counts(normalize=True) * 100\n",
    "print(\"Balanced Class Distribution:\\n\", new_class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb482f2c-203c-4a7e-a5c3-3a972e183d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2778, 33)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1818b09c-3bb6-49db-8626-592d7bb1daae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Dataset After One-Hot Encoding:\n",
      "   Age  Gender        BMI  Smoking  AlcoholConsumption  PhysicalActivity  \\\n",
      "0   80       1  16.834968        0           19.053565          4.352272   \n",
      "1   88       1  35.353244        1            0.768943          8.883326   \n",
      "2   63       0  32.726550        0           16.971929          8.569751   \n",
      "3   75       1  38.668960        1            6.669039          7.328895   \n",
      "4   72       0  30.646711        0            4.452856          0.768016   \n",
      "\n",
      "   DietQuality  SleepQuality  FamilyHistoryAlzheimers  CardiovascularDisease  \\\n",
      "0     3.432055      7.361459                        0                      0   \n",
      "1     4.085773      7.450835                        0                      0   \n",
      "2     8.744619      9.227229                        0                      0   \n",
      "3     7.973275      9.966551                        0                      0   \n",
      "4     4.978013      7.715735                        0                      1   \n",
      "\n",
      "   ...  Forgetfulness  Diagnosis  Ethnicity_0  Ethnicity_1  Ethnicity_2  \\\n",
      "0  ...              0          0          0.0          1.0          0.0   \n",
      "1  ...              1          1          1.0          0.0          0.0   \n",
      "2  ...              0          1          0.0          0.0          1.0   \n",
      "3  ...              1          0          0.0          0.0          0.0   \n",
      "4  ...              0          0          0.0          1.0          0.0   \n",
      "\n",
      "   Ethnicity_3  EducationLevel_0  EducationLevel_1  EducationLevel_2  \\\n",
      "0          0.0               0.0               1.0               0.0   \n",
      "1          0.0               0.0               1.0               0.0   \n",
      "2          0.0               0.0               1.0               0.0   \n",
      "3          1.0               0.0               0.0               1.0   \n",
      "4          0.0               0.0               0.0               1.0   \n",
      "\n",
      "   EducationLevel_3  \n",
      "0               0.0  \n",
      "1               0.0  \n",
      "2               0.0  \n",
      "3               0.0  \n",
      "4               0.0  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Step 1: Select the nominal categorical features\n",
    "nominal_features = ['Ethnicity', 'EducationLevel']\n",
    "\n",
    "# Step 2: Initialize One-Hot Encoder without dropping any category\n",
    "ohe = OneHotEncoder(drop=None, sparse_output=False)  # Keep all categories\n",
    "\n",
    "# Step 3: Fit and transform the categorical features\n",
    "encoded_features = ohe.fit_transform(balanced_data[nominal_features])\n",
    "\n",
    "# Step 4: Convert the encoded features into a DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=ohe.get_feature_names_out(nominal_features))\n",
    "\n",
    "# Step 5: Drop the original categorical columns and merge encoded features\n",
    "data = balanced_data.drop(columns=nominal_features).reset_index(drop=True)  # Drop original categorical columns\n",
    "data = pd.concat([data, encoded_df], axis=1)  # Merge encoded data\n",
    "\n",
    "# Step 6: Verify the transformed data\n",
    "print(\"Updated Dataset After One-Hot Encoding:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fcdd257-fe6c-4e47-82a6-57dc7193cf12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1520, 39)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a0943aa-13ab-4659-9e3b-307c5992c550",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'FunctionalAssessment', 'ADL', 'MemoryComplaints', 'MMSE', 'BehavioralProblems', 'SleepQuality'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f83a797-b3f3-4523-a131-aa8897449086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_features = ['FunctionalAssessment', 'ADL', 'MemoryComplaints', 'MMSE', 'BehavioralProblems', 'SleepQuality', 'CholesterolHDL', 'CholesterolLDL', 'BMI', 'CholesterolTriglycerides', 'Age', 'PhysicalActivity', 'DietQuality', 'DiastolicBP', 'Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19e86c59-78ca-4701-abcf-4041b3517dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[selected_features]  \n",
    "y = data['Diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ccf4b70-d8b8-4ff7-a70d-cc2e9a62d400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1520, 6)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "041df1fb-9f06-420f-9baf-a79b43476325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb9e59ac-83fd-4b4d-843b-9c967c5e98f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of 0s: 151\n",
      "Count of 1s: 153\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Count the occurrences of 0 and 1 in y_test\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "count_dict = dict(zip(unique, counts))\n",
    "\n",
    "# Print the results\n",
    "print(f\"Count of 0s: {count_dict.get(0, 0)}\")\n",
    "print(f\"Count of 1s: {count_dict.get(1, 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb0dabc5-1a53-49cf-8aea-00f4fd58f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data and transform both train and test separately\n",
    "X_train_scaled = scaler.fit_transform(X_train)  \n",
    "X_test_scaled = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8a744d-2ed1-4823-99c0-f78884074e9c",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c726f6d-e92c-4af3-bae1-4182bbe3c566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9013157894736842\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       151\n",
      "           1       0.90      0.91      0.90       153\n",
      "\n",
      "    accuracy                           0.90       304\n",
      "   macro avg       0.90      0.90      0.90       304\n",
      "weighted avg       0.90      0.90      0.90       304\n",
      "\n",
      "Confusion Matrix:\n",
      " [[135  16]\n",
      " [ 14 139]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt.fit(X_train_scaled, y_train)\n",
    "\n",
    "dt_y_pred = dt.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, dt_y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, dt_y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, dt_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a088435c-08cb-4e6c-bdd1-c7a67a4d908d",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd8212e4-496e-46e4-898d-1e3a9c586038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9407894736842105\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       151\n",
      "           1       0.96      0.92      0.94       153\n",
      "\n",
      "    accuracy                           0.94       304\n",
      "   macro avg       0.94      0.94      0.94       304\n",
      "weighted avg       0.94      0.94      0.94       304\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[145   6]\n",
      " [ 12 141]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=100)  # 100 trees in the forest\n",
    "\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "rf_y_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, rf_y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, rf_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2105eccc-37bf-4194-ad55-3ac38fb47f69",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8ea569b3-5acd-4af2-8b01-bc0c7322e123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9342105263157895\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94       151\n",
      "           1       0.95      0.92      0.93       153\n",
      "\n",
      "    accuracy                           0.93       304\n",
      "   macro avg       0.93      0.93      0.93       304\n",
      "weighted avg       0.93      0.93      0.93       304\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[144   7]\n",
      " [ 13 140]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "xgb = XGBClassifier(random_state=42, n_estimators=100, eval_metric='logloss')\n",
    "\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "xgb_y_pred = xgb.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, xgb_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, xgb_y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, xgb_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82cabf0-f6db-462a-a49e-269efe251eff",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7336bab7-c969-41d1-81f4-d6c218d76d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\chapp\\anaconda3\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: graphviz in c:\\users\\chapp\\anaconda3\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from catboost) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\chapp\\anaconda3\\lib\\site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from catboost) (1.14.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\chapp\\anaconda3\\lib\\site-packages (from catboost) (5.22.0)\n",
      "Requirement already satisfied: six in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chapp\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\chapp\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (3.2.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\chapp\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da4863f5-7145-44c5-98fd-3cc770893f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.944078947368421\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       151\n",
      "           1       0.96      0.93      0.94       153\n",
      "\n",
      "    accuracy                           0.94       304\n",
      "   macro avg       0.94      0.94      0.94       304\n",
      "weighted avg       0.94      0.94      0.94       304\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[145   6]\n",
      " [ 11 142]]\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "catboost = CatBoostClassifier(random_state=42, iterations=100, verbose=0)  # 100 iterations, silent training\n",
    "\n",
    "catboost.fit(X_train_scaled, y_train)\n",
    "\n",
    "catboost_y_pred = catboost.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, catboost_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, catboost_y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, catboost_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d038a79a-b893-4a53-9530-bd3c62039476",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c3956d4c-4f57-45f1-87ce-19e6f96cafc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9046052631578947\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90       151\n",
      "           1       0.88      0.94      0.91       153\n",
      "\n",
      "    accuracy                           0.90       304\n",
      "   macro avg       0.91      0.90      0.90       304\n",
      "weighted avg       0.91      0.90      0.90       304\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[131  20]\n",
      " [  9 144]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "adaboost = AdaBoostClassifier(random_state=42, n_estimators=100)  # 100 weak learners\n",
    "\n",
    "adaboost.fit(X_train_scaled, y_train)\n",
    "\n",
    "adaboost_y_pred = adaboost.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, adaboost_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, adaboost_y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, adaboost_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2610c77-017c-420d-ab29-75c29fe154e0",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d7ec624f-cade-47b4-a807-5c49ac181172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9210526315789473\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       151\n",
      "           1       0.94      0.90      0.92       153\n",
      "\n",
      "    accuracy                           0.92       304\n",
      "   macro avg       0.92      0.92      0.92       304\n",
      "weighted avg       0.92      0.92      0.92       304\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[142   9]\n",
      " [ 15 138]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize SVM Classifier\n",
    "svm = SVC(random_state=42, kernel='rbf')  # Using RBF kernel (default)\n",
    "\n",
    "# Train the model\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "svm_y_pred = svm.predict(X_test_scaled)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, svm_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, svm_y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, svm_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768dc570-7170-4065-b091-76de4cdc2dac",
   "metadata": {},
   "source": [
    "# Stratified cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eea95a-c1ae-4312-85a1-19ac80bfbcd3",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "772afb70-3fb5-48a6-ad61-34a9aedd65e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Accuracy: 0.924\n",
      "  Precision: 0.927\n",
      "  Recall: 0.924\n",
      "  F1-Score: 0.925\n",
      "\n",
      "Fold 2:\n",
      "  Accuracy: 0.884\n",
      "  Precision: 0.884\n",
      "  Recall: 0.884\n",
      "  F1-Score: 0.884\n",
      "\n",
      "Fold 3:\n",
      "  Accuracy: 0.866\n",
      "  Precision: 0.866\n",
      "  Recall: 0.866\n",
      "  F1-Score: 0.866\n",
      "\n",
      "Fold 4:\n",
      "  Accuracy: 0.890\n",
      "  Precision: 0.890\n",
      "  Recall: 0.890\n",
      "  F1-Score: 0.890\n",
      "\n",
      "Fold 5:\n",
      "  Accuracy: 0.913\n",
      "  Precision: 0.913\n",
      "  Recall: 0.913\n",
      "  F1-Score: 0.913\n",
      "\n",
      "Fold 6:\n",
      "  Accuracy: 0.872\n",
      "  Precision: 0.871\n",
      "  Recall: 0.872\n",
      "  F1-Score: 0.870\n",
      "\n",
      "Fold 7:\n",
      "  Accuracy: 0.890\n",
      "  Precision: 0.889\n",
      "  Recall: 0.890\n",
      "  F1-Score: 0.888\n",
      "\n",
      "Fold 8:\n",
      "  Accuracy: 0.866\n",
      "  Precision: 0.867\n",
      "  Recall: 0.866\n",
      "  F1-Score: 0.867\n",
      "\n",
      "Fold 9:\n",
      "  Accuracy: 0.930\n",
      "  Precision: 0.930\n",
      "  Recall: 0.930\n",
      "  F1-Score: 0.930\n",
      "\n",
      "Fold 10:\n",
      "  Accuracy: 0.901\n",
      "  Precision: 0.901\n",
      "  Recall: 0.901\n",
      "  F1-Score: 0.901\n",
      "\n",
      "\n",
      "Final Cross-Validation Results (Average Over 10 Folds):\n",
      "  Accuracy: 0.894 ± 0.022\n",
      "  Precision: 0.894 ± 0.022\n",
      "  Recall: 0.894 ± 0.022\n",
      "  F1-Score: 0.893 ± 0.022\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Decision Tree Classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Apply 10-Fold Stratified Cross-Validation\n",
    "stratified_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform 10-Fold Cross-Validation\n",
    "for fold, (train_idx, test_idx) in enumerate(stratified_cv.split(X_train_scaled, y_train), 1):\n",
    "    X_train_fold, X_test_fold = X_train_scaled[train_idx], X_train_scaled[test_idx]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    # Train model on current fold\n",
    "    dt.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold = dt.predict(X_test_fold)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    precision = precision_score(y_test_fold, y_pred_fold, average='weighted')  # Weighted for class imbalance\n",
    "    recall = recall_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "    f1 = f1_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "\n",
    "    # Store results\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    # Print metrics for current fold\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  F1-Score: {f1:.3f}\\n\")\n",
    "\n",
    "# Print average results across all folds\n",
    "print(\"\\nFinal Cross-Validation Results (Average Over 10 Folds):\")\n",
    "print(f\"  Accuracy: {np.mean(accuracy_scores):.3f} ± {np.std(accuracy_scores):.3f}\")\n",
    "print(f\"  Precision: {np.mean(precision_scores):.3f} ± {np.std(precision_scores):.3f}\")\n",
    "print(f\"  Recall: {np.mean(recall_scores):.3f} ± {np.std(recall_scores):.3f}\")\n",
    "print(f\"  F1-Score: {np.mean(f1_scores):.3f} ± {np.std(f1_scores):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99af779d-18c8-49d7-9f1e-41825166f447",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5266f0ea-fab6-4599-9bcd-097d14bb978b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Accuracy: 0.951\n",
      "  Precision: 0.955\n",
      "  Recall: 0.951\n",
      "  F1-Score: 0.951\n",
      "\n",
      "Fold 2:\n",
      "  Accuracy: 0.934\n",
      "  Precision: 0.934\n",
      "  Recall: 0.934\n",
      "  F1-Score: 0.934\n",
      "\n",
      "Fold 3:\n",
      "  Accuracy: 0.951\n",
      "  Precision: 0.951\n",
      "  Recall: 0.951\n",
      "  F1-Score: 0.951\n",
      "\n",
      "Fold 4:\n",
      "  Accuracy: 0.975\n",
      "  Precision: 0.977\n",
      "  Recall: 0.975\n",
      "  F1-Score: 0.975\n",
      "\n",
      "Fold 5:\n",
      "  Accuracy: 0.967\n",
      "  Precision: 0.968\n",
      "  Recall: 0.967\n",
      "  F1-Score: 0.967\n",
      "\n",
      "Fold 6:\n",
      "  Accuracy: 0.951\n",
      "  Precision: 0.953\n",
      "  Recall: 0.951\n",
      "  F1-Score: 0.951\n",
      "\n",
      "Fold 7:\n",
      "  Accuracy: 0.917\n",
      "  Precision: 0.921\n",
      "  Recall: 0.917\n",
      "  F1-Score: 0.917\n",
      "\n",
      "Fold 8:\n",
      "  Accuracy: 0.942\n",
      "  Precision: 0.942\n",
      "  Recall: 0.942\n",
      "  F1-Score: 0.942\n",
      "\n",
      "Fold 9:\n",
      "  Accuracy: 0.926\n",
      "  Precision: 0.931\n",
      "  Recall: 0.926\n",
      "  F1-Score: 0.925\n",
      "\n",
      "Fold 10:\n",
      "  Accuracy: 0.950\n",
      "  Precision: 0.951\n",
      "  Recall: 0.950\n",
      "  F1-Score: 0.950\n",
      "\n",
      "\n",
      "Final Cross-Validation Results (Average Over 10 Folds):\n",
      "  Accuracy: 0.947 ± 0.017\n",
      "  Precision: 0.948 ± 0.016\n",
      "  Recall: 0.947 ± 0.017\n",
      "  F1-Score: 0.946 ± 0.017\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=100)  # 100 trees in the forest\n",
    "\n",
    "# Apply 10-Fold Stratified Cross-Validation\n",
    "stratified_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform 10-Fold Cross-Validation\n",
    "for fold, (train_idx, test_idx) in enumerate(stratified_cv.split(X_train_scaled, y_train), 1):\n",
    "    X_train_fold, X_test_fold = X_train_scaled[train_idx], X_train_scaled[test_idx]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    # Train model on current fold\n",
    "    rf.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold = rf.predict(X_test_fold)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    precision = precision_score(y_test_fold, y_pred_fold, average='weighted')  # Weighted for class imbalance\n",
    "    recall = recall_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "    f1 = f1_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "\n",
    "    # Store results\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    # Print metrics for current fold\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  F1-Score: {f1:.3f}\\n\")\n",
    "\n",
    "# Print average results across all folds\n",
    "print(\"\\nFinal Cross-Validation Results (Average Over 10 Folds):\")\n",
    "print(f\"  Accuracy: {np.mean(accuracy_scores):.3f} ± {np.std(accuracy_scores):.3f}\")\n",
    "print(f\"  Precision: {np.mean(precision_scores):.3f} ± {np.std(precision_scores):.3f}\")\n",
    "print(f\"  Recall: {np.mean(recall_scores):.3f} ± {np.std(recall_scores):.3f}\")\n",
    "print(f\"  F1-Score: {np.mean(f1_scores):.3f} ± {np.std(f1_scores):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d21c57-b363-4944-bdb1-92c09b74caad",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c24d7d25-bcc6-46c7-a57a-58cf59416004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Accuracy: 0.951\n",
      "  Precision: 0.955\n",
      "  Recall: 0.951\n",
      "  F1-Score: 0.951\n",
      "\n",
      "Fold 2:\n",
      "  Accuracy: 0.926\n",
      "  Precision: 0.926\n",
      "  Recall: 0.926\n",
      "  F1-Score: 0.926\n",
      "\n",
      "Fold 3:\n",
      "  Accuracy: 0.951\n",
      "  Precision: 0.951\n",
      "  Recall: 0.951\n",
      "  F1-Score: 0.951\n",
      "\n",
      "Fold 4:\n",
      "  Accuracy: 0.975\n",
      "  Precision: 0.977\n",
      "  Recall: 0.975\n",
      "  F1-Score: 0.975\n",
      "\n",
      "Fold 5:\n",
      "  Accuracy: 0.967\n",
      "  Precision: 0.968\n",
      "  Recall: 0.967\n",
      "  F1-Score: 0.967\n",
      "\n",
      "Fold 6:\n",
      "  Accuracy: 0.959\n",
      "  Precision: 0.959\n",
      "  Recall: 0.959\n",
      "  F1-Score: 0.959\n",
      "\n",
      "Fold 7:\n",
      "  Accuracy: 0.934\n",
      "  Precision: 0.938\n",
      "  Recall: 0.934\n",
      "  F1-Score: 0.934\n",
      "\n",
      "Fold 8:\n",
      "  Accuracy: 0.950\n",
      "  Precision: 0.951\n",
      "  Recall: 0.950\n",
      "  F1-Score: 0.950\n",
      "\n",
      "Fold 9:\n",
      "  Accuracy: 0.917\n",
      "  Precision: 0.921\n",
      "  Recall: 0.917\n",
      "  F1-Score: 0.917\n",
      "\n",
      "Fold 10:\n",
      "  Accuracy: 0.950\n",
      "  Precision: 0.951\n",
      "  Recall: 0.950\n",
      "  F1-Score: 0.950\n",
      "\n",
      "\n",
      "Final Cross-Validation Results (Average Over 10 Folds):\n",
      "  Accuracy: 0.948 ± 0.017\n",
      "  Precision: 0.950 ± 0.016\n",
      "  Recall: 0.948 ± 0.017\n",
      "  F1-Score: 0.948 ± 0.017\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize CatBoost Classifier\n",
    "catboost = CatBoostClassifier(random_state=42, iterations=100, verbose=0)  # 100 iterations, silent training\n",
    "\n",
    "# Apply 10-Fold Stratified Cross-Validation\n",
    "stratified_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform 10-Fold Cross-Validation\n",
    "for fold, (train_idx, test_idx) in enumerate(stratified_cv.split(X_train_scaled, y_train), 1):\n",
    "    X_train_fold, X_test_fold = X_train_scaled[train_idx], X_train_scaled[test_idx]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    # Train model on current fold\n",
    "    catboost.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold = catboost.predict(X_test_fold)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    precision = precision_score(y_test_fold, y_pred_fold, average='weighted')  # Weighted for class imbalance\n",
    "    recall = recall_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "    f1 = f1_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "\n",
    "    # Store results\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    # Print metrics for current fold\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  F1-Score: {f1:.3f}\\n\")\n",
    "\n",
    "# Print average results across all folds\n",
    "print(\"\\nFinal Cross-Validation Results (Average Over 10 Folds):\")\n",
    "print(f\"  Accuracy: {np.mean(accuracy_scores):.3f} ± {np.std(accuracy_scores):.3f}\")\n",
    "print(f\"  Precision: {np.mean(precision_scores):.3f} ± {np.std(precision_scores):.3f}\")\n",
    "print(f\"  Recall: {np.mean(recall_scores):.3f} ± {np.std(recall_scores):.3f}\")\n",
    "print(f\"  F1-Score: {np.mean(f1_scores):.3f} ± {np.std(f1_scores):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d182bbd-fd53-4f5b-a7c2-ab8282a42569",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a98c72c9-dbba-442a-8751-58bad17f458c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:12:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Accuracy: 0.977\n",
      "  Precision: 0.977\n",
      "  Recall: 0.977\n",
      "  F1-Score: 0.977\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:12:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2:\n",
      "  Accuracy: 0.948\n",
      "  Precision: 0.948\n",
      "  Recall: 0.948\n",
      "  F1-Score: 0.947\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:12:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3:\n",
      "  Accuracy: 0.924\n",
      "  Precision: 0.924\n",
      "  Recall: 0.924\n",
      "  F1-Score: 0.924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:12:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4:\n",
      "  Accuracy: 0.942\n",
      "  Precision: 0.943\n",
      "  Recall: 0.942\n",
      "  F1-Score: 0.942\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:12:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5:\n",
      "  Accuracy: 0.953\n",
      "  Precision: 0.953\n",
      "  Recall: 0.953\n",
      "  F1-Score: 0.953\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:12:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6:\n",
      "  Accuracy: 0.953\n",
      "  Precision: 0.955\n",
      "  Recall: 0.953\n",
      "  F1-Score: 0.953\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:12:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7:\n",
      "  Accuracy: 0.924\n",
      "  Precision: 0.925\n",
      "  Recall: 0.924\n",
      "  F1-Score: 0.924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:12:07] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8:\n",
      "  Accuracy: 0.953\n",
      "  Precision: 0.954\n",
      "  Recall: 0.953\n",
      "  F1-Score: 0.953\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:12:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9:\n",
      "  Accuracy: 0.959\n",
      "  Precision: 0.960\n",
      "  Recall: 0.959\n",
      "  F1-Score: 0.959\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:12:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10:\n",
      "  Accuracy: 0.977\n",
      "  Precision: 0.977\n",
      "  Recall: 0.977\n",
      "  F1-Score: 0.977\n",
      "\n",
      "\n",
      "Final Cross-Validation Results (Average Over 10 Folds):\n",
      "  Accuracy: 0.951 ± 0.017\n",
      "  Precision: 0.951 ± 0.017\n",
      "  Recall: 0.951 ± 0.017\n",
      "  F1-Score: 0.951 ± 0.017\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize XGBoost Classifier\n",
    "xgb = XGBClassifier(random_state=42, n_estimators=100, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Apply 10-Fold Stratified Cross-Validation\n",
    "stratified_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform 10-Fold Cross-Validation\n",
    "for fold, (train_idx, test_idx) in enumerate(stratified_cv.split(X_train_scaled, y_train), 1):\n",
    "    X_train_fold, X_test_fold = X_train_scaled[train_idx], X_train_scaled[test_idx]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    # Train model on current fold\n",
    "    xgb.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold = xgb.predict(X_test_fold)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    precision = precision_score(y_test_fold, y_pred_fold, average='weighted')  # Weighted for class imbalance\n",
    "    recall = recall_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "    f1 = f1_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "\n",
    "    # Store results\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    # Print metrics for current fold\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  F1-Score: {f1:.3f}\\n\")\n",
    "\n",
    "# Print average results across all folds\n",
    "print(\"\\nFinal Cross-Validation Results (Average Over 10 Folds):\")\n",
    "print(f\"  Accuracy: {np.mean(accuracy_scores):.3f} ± {np.std(accuracy_scores):.3f}\")\n",
    "print(f\"  Precision: {np.mean(precision_scores):.3f} ± {np.std(precision_scores):.3f}\")\n",
    "print(f\"  Recall: {np.mean(recall_scores):.3f} ± {np.std(recall_scores):.3f}\")\n",
    "print(f\"  F1-Score: {np.mean(f1_scores):.3f} ± {np.std(f1_scores):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdad0702-6f31-45b1-bf0e-084f82fade35",
   "metadata": {},
   "source": [
    "## stacking on the top 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1c9f3ae8-6f09-4dac-9ddc-cb5d94d606df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Stacking Classifier (Test Set)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       151\n",
      "           1       0.94      0.92      0.93       153\n",
      "\n",
      "    accuracy                           0.93       304\n",
      "   macro avg       0.93      0.93      0.93       304\n",
      "weighted avg       0.93      0.93      0.93       304\n",
      "\n",
      "[[142   9]\n",
      " [ 12 141]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# Create the individual classifiers\n",
    "rf = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "xgb = make_pipeline(StandardScaler(), XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss'))\n",
    "catboost = make_pipeline(StandardScaler(), CatBoostClassifier(iterations=100, verbose=0, random_state=42))\n",
    "\n",
    "# Create the stacking classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[('rf', rf), ('xgb', xgb), ('catboost', catboost)],  # Base models\n",
    "    final_estimator=RandomForestClassifier(n_estimators=100, random_state=42)  # Meta learner\n",
    ")\n",
    "\n",
    "\n",
    "# Perform cross-validation predictions\n",
    "stacking_preds = cross_val_predict(stacking_clf, X_train, y_train, cv=5)\n",
    "\n",
    "# Train the classifiers on the full training set\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "stacking_test_preds = stacking_clf.predict(X_test)\n",
    "\n",
    "# Function to print classification report\n",
    "def print_classification_report(y_true, y_pred, title):\n",
    "    print(f\"\\n{title}\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Print classification reports\n",
    "print_classification_report(y_test, stacking_test_preds, \"Classification Report for Stacking Classifier (Test Set)\")\n",
    "print(confusion_matrix(y_test, stacking_test_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378736b1-ec39-4f70-a09d-363d450ea800",
   "metadata": {},
   "source": [
    "# parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99e17a6-8f3b-4202-b5b8-fbf7790e6f67",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b6616e-eb2c-41d1-b24f-f9da86559f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of trees\n",
    "    'max_depth': [10, 20, None],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum samples required at a leaf node\n",
    "    'max_features': ['sqrt', 'log2'],  # Number of features to consider for best split\n",
    "    'bootstrap': [True, False]  # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform Grid Search with 5-Fold Cross-Validation\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit on training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train Random Forest with best parameters\n",
    "best_rf = RandomForestClassifier(**best_params, random_state=42)\n",
    "best_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_y_pred = best_rf.predict(X_test_scaled)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, rf_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, rf_y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, rf_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1e2ff77a-8a38-4b03-9ca1-06f72fa7e752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Hyperparameters: {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': True}\n",
      "\n",
      "Accuracy: 0.9407894736842105\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       151\n",
      "           1       0.96      0.92      0.94       153\n",
      "\n",
      "    accuracy                           0.94       304\n",
      "   macro avg       0.94      0.94      0.94       304\n",
      "weighted avg       0.94      0.94      0.94       304\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[145   6]\n",
      " [ 12 141]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Define the hyperparameter distribution\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of trees\n",
    "    'max_depth': [10, 20, None],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum samples required at a leaf node\n",
    "    'max_features': ['sqrt', 'log2'],  # Number of features to consider for best split\n",
    "    'bootstrap': [True, False]  # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform Randomized Search with 5-Fold Cross-Validation\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=20, cv=5,\n",
    "                                   scoring='accuracy', n_jobs=-1, verbose=1, random_state=42)\n",
    "\n",
    "# Fit on training data\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = random_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train Random Forest with best parameters\n",
    "best_rf = RandomForestClassifier(**best_params, random_state=42)\n",
    "best_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_y_pred = best_rf.predict(X_test_scaled)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, rf_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, rf_y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, rf_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd42791c-45c9-4e41-a8c4-8910b775be56",
   "metadata": {},
   "source": [
    "### cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9770fe8-1132-4137-a55c-9938bb68265b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'iterations': [100, 200, 500],  # Number of boosting iterations\n",
    "    'learning_rate': [0.01, 0.05, 0.1],  # Step size shrinkage to prevent overfitting\n",
    "    'depth': [4, 6, 8, 10],  # Maximum depth of the trees\n",
    "    'l2_leaf_reg': [1, 3, 5, 7],  # L2 regularization to prevent overfitting\n",
    "    'border_count': [32, 64, 128],  # Number of bins used for numeric feature quantization\n",
    "}\n",
    "\n",
    "# Initialize the CatBoost model\n",
    "catboost = CatBoostClassifier(random_state=42, verbose=0)\n",
    "\n",
    "# Perform Grid Search with 5-Fold Cross-Validation\n",
    "grid_search = GridSearchCV(catboost, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit on training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train CatBoost with best parameters\n",
    "best_catboost = CatBoostClassifier(**best_params, random_state=42, verbose=0)\n",
    "best_catboost.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "catboost_y_pred = best_catboost.predict(X_test_scaled)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, catboost_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, catboost_y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, catboost_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9677a00-563f-4820-bdf9-a635041e1320",
   "metadata": {},
   "source": [
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8d98dc60-380a-4ae6-bf49-34f4b2d4b35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:34:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5785310\ttotal: 4.73ms\tremaining: 4.72s\n",
      "100:\tlearn: 0.1071573\ttotal: 455ms\tremaining: 4.05s\n",
      "200:\tlearn: 0.0650612\ttotal: 849ms\tremaining: 3.38s\n",
      "300:\tlearn: 0.0431047\ttotal: 1.27s\tremaining: 2.96s\n",
      "400:\tlearn: 0.0304908\ttotal: 1.7s\tremaining: 2.54s\n",
      "500:\tlearn: 0.0226870\ttotal: 2.15s\tremaining: 2.14s\n",
      "600:\tlearn: 0.0177688\ttotal: 2.59s\tremaining: 1.72s\n",
      "700:\tlearn: 0.0144000\ttotal: 3.05s\tremaining: 1.3s\n",
      "800:\tlearn: 0.0122343\ttotal: 3.49s\tremaining: 867ms\n",
      "900:\tlearn: 0.0104172\ttotal: 3.94s\tremaining: 433ms\n",
      "999:\tlearn: 0.0093536\ttotal: 4.37s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:34:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5733256\ttotal: 5.31ms\tremaining: 5.31s\n",
      "100:\tlearn: 0.0982809\ttotal: 464ms\tremaining: 4.13s\n",
      "200:\tlearn: 0.0584185\ttotal: 921ms\tremaining: 3.66s\n",
      "300:\tlearn: 0.0366199\ttotal: 1.36s\tremaining: 3.17s\n",
      "400:\tlearn: 0.0244561\ttotal: 1.8s\tremaining: 2.69s\n",
      "500:\tlearn: 0.0183659\ttotal: 2.21s\tremaining: 2.2s\n",
      "600:\tlearn: 0.0142048\ttotal: 2.62s\tremaining: 1.74s\n",
      "700:\tlearn: 0.0116738\ttotal: 2.98s\tremaining: 1.27s\n",
      "800:\tlearn: 0.0097143\ttotal: 3.37s\tremaining: 838ms\n",
      "900:\tlearn: 0.0087821\ttotal: 3.79s\tremaining: 416ms\n",
      "999:\tlearn: 0.0078476\ttotal: 4.19s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:34:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5780561\ttotal: 6.23ms\tremaining: 6.22s\n",
      "100:\tlearn: 0.1111752\ttotal: 395ms\tremaining: 3.52s\n",
      "200:\tlearn: 0.0672155\ttotal: 808ms\tremaining: 3.21s\n",
      "300:\tlearn: 0.0414508\ttotal: 1.25s\tremaining: 2.9s\n",
      "400:\tlearn: 0.0293439\ttotal: 1.7s\tremaining: 2.54s\n",
      "500:\tlearn: 0.0211616\ttotal: 2.15s\tremaining: 2.14s\n",
      "600:\tlearn: 0.0167282\ttotal: 2.5s\tremaining: 1.66s\n",
      "700:\tlearn: 0.0135363\ttotal: 2.9s\tremaining: 1.24s\n",
      "800:\tlearn: 0.0114164\ttotal: 3.25s\tremaining: 807ms\n",
      "900:\tlearn: 0.0099901\ttotal: 3.8s\tremaining: 417ms\n",
      "999:\tlearn: 0.0092753\ttotal: 4.25s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:34:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5768994\ttotal: 7.39ms\tremaining: 7.38s\n",
      "100:\tlearn: 0.1145030\ttotal: 371ms\tremaining: 3.3s\n",
      "200:\tlearn: 0.0714900\ttotal: 728ms\tremaining: 2.89s\n",
      "300:\tlearn: 0.0461566\ttotal: 1.09s\tremaining: 2.52s\n",
      "400:\tlearn: 0.0335462\ttotal: 1.43s\tremaining: 2.14s\n",
      "500:\tlearn: 0.0247397\ttotal: 1.82s\tremaining: 1.81s\n",
      "600:\tlearn: 0.0188524\ttotal: 2.24s\tremaining: 1.49s\n",
      "700:\tlearn: 0.0156000\ttotal: 2.64s\tremaining: 1.13s\n",
      "800:\tlearn: 0.0132015\ttotal: 3.04s\tremaining: 756ms\n",
      "900:\tlearn: 0.0117447\ttotal: 3.46s\tremaining: 380ms\n",
      "999:\tlearn: 0.0107278\ttotal: 3.87s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:34:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5719751\ttotal: 4.77ms\tremaining: 4.76s\n",
      "100:\tlearn: 0.0996137\ttotal: 462ms\tremaining: 4.11s\n",
      "200:\tlearn: 0.0573304\ttotal: 934ms\tremaining: 3.71s\n",
      "300:\tlearn: 0.0358949\ttotal: 1.39s\tremaining: 3.23s\n",
      "400:\tlearn: 0.0249307\ttotal: 1.84s\tremaining: 2.75s\n",
      "500:\tlearn: 0.0181705\ttotal: 2.34s\tremaining: 2.33s\n",
      "600:\tlearn: 0.0142450\ttotal: 2.82s\tremaining: 1.87s\n",
      "700:\tlearn: 0.0114224\ttotal: 3.29s\tremaining: 1.41s\n",
      "800:\tlearn: 0.0096208\ttotal: 3.69s\tremaining: 918ms\n",
      "900:\tlearn: 0.0084883\ttotal: 4.11s\tremaining: 451ms\n",
      "999:\tlearn: 0.0078242\ttotal: 4.54s\tremaining: 0us\n",
      "Random Forest Scores: [0.9494949494949495, 0.9324324324324325, 0.9494949494949495, 0.9459459459459459, 0.9169435215946844]\n",
      "XGBoost Scores: [0.9337748344370861, 0.9220338983050848, 0.9292929292929293, 0.9395973154362416, 0.9042904290429042]\n",
      "CatBoost Scores: [0.9431438127090301, 0.9403973509933775, 0.9504950495049505, 0.9530201342281879, 0.9139072847682119]\n",
      "Friedman Test Statistic: 7.6000000000000085\n",
      "P-value: 0.0223707718561655\n",
      "Random Forest: Average Rank = 1.60\n",
      "XGBoost: Average Rank = 3.00\n",
      "CatBoost: Average Rank = 1.40\n",
      "\n",
      "Model Rankings:\n",
      "1. CatBoost (Average Rank: 1.40)\n",
      "2. Random Forest (Average Rank: 1.60)\n",
      "3. XGBoost (Average Rank: 3.00)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import friedmanchisquare, rankdata\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    'CatBoost': CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=6, verbose=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Initialize K-Fold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize a dictionary to store scores\n",
    "model_scores = {model_name: [] for model_name in models.keys()}\n",
    "\n",
    "# Perform K-Fold Cross-Validation\n",
    "for train_idx, test_idx in kfold.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        score = f1_score(y_test, y_pred)  # You can use other metrics like F1-score\n",
    "        model_scores[model_name].append(score)\n",
    "\n",
    "# Print scores\n",
    "for model_name, scores in model_scores.items():\n",
    "    print(f\"{model_name} Scores: {scores}\")\n",
    "\n",
    "\n",
    "# Convert model scores to a matrix\n",
    "scores_matrix = np.array([model_scores[model_name] for model_name in models.keys()])\n",
    "\n",
    "# Perform Friedman Test\n",
    "stat, p = friedmanchisquare(*scores_matrix)\n",
    "print(\"Friedman Test Statistic:\", stat)\n",
    "print(\"P-value:\", p)\n",
    "\n",
    "# Rank models for each fold\n",
    "ranks = np.array([rankdata(-fold_scores) for fold_scores in scores_matrix.T])\n",
    "avg_ranks = ranks.mean(axis=0)\n",
    "\n",
    "# Print model rankings\n",
    "model_names = list(models.keys())\n",
    "for model, rank in zip(model_names, avg_ranks):\n",
    "    print(f\"{model}: Average Rank = {rank:.2f}\")\n",
    "\n",
    "# Sort and display rankings\n",
    "sorted_models = sorted(zip(model_names, avg_ranks), key=lambda x: x[1])\n",
    "print(\"\\nModel Rankings:\")\n",
    "for i, (model, rank) in enumerate(sorted_models, 1):\n",
    "    print(f\"{i}. {model} (Average Rank: {rank:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750e84f6-8151-4dcc-ad57-4c95983bf336",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
