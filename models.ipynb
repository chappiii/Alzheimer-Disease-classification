{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee76958b-883c-4995-bdd4-34842de8464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "746d9360-11ac-4465-9ba4-35bd6a294788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2149, 35)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "data = pd.read_csv(\"alzheimers_disease_data.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9557af2e-d86e-4ddc-b724-e3b921a77aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholConsumption</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>DietQuality</th>\n",
       "      <th>SleepQuality</th>\n",
       "      <th>...</th>\n",
       "      <th>FunctionalAssessment</th>\n",
       "      <th>MemoryComplaints</th>\n",
       "      <th>BehavioralProblems</th>\n",
       "      <th>ADL</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Disorientation</th>\n",
       "      <th>PersonalityChanges</th>\n",
       "      <th>DifficultyCompletingTasks</th>\n",
       "      <th>Forgetfulness</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22.927749</td>\n",
       "      <td>0</td>\n",
       "      <td>13.297218</td>\n",
       "      <td>6.327112</td>\n",
       "      <td>1.347214</td>\n",
       "      <td>9.025679</td>\n",
       "      <td>...</td>\n",
       "      <td>6.518877</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.725883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.827681</td>\n",
       "      <td>0</td>\n",
       "      <td>4.542524</td>\n",
       "      <td>7.619885</td>\n",
       "      <td>0.518767</td>\n",
       "      <td>7.151293</td>\n",
       "      <td>...</td>\n",
       "      <td>7.118696</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.592424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17.795882</td>\n",
       "      <td>0</td>\n",
       "      <td>19.555085</td>\n",
       "      <td>7.844988</td>\n",
       "      <td>1.826335</td>\n",
       "      <td>9.673574</td>\n",
       "      <td>...</td>\n",
       "      <td>5.895077</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.119548</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.800817</td>\n",
       "      <td>1</td>\n",
       "      <td>12.209266</td>\n",
       "      <td>8.428001</td>\n",
       "      <td>7.435604</td>\n",
       "      <td>8.392554</td>\n",
       "      <td>...</td>\n",
       "      <td>8.965106</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.481226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.716974</td>\n",
       "      <td>0</td>\n",
       "      <td>18.454356</td>\n",
       "      <td>6.310461</td>\n",
       "      <td>0.795498</td>\n",
       "      <td>5.597238</td>\n",
       "      <td>...</td>\n",
       "      <td>6.045039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Ethnicity  EducationLevel        BMI  Smoking  \\\n",
       "0   73       0          0               2  22.927749        0   \n",
       "1   89       0          0               0  26.827681        0   \n",
       "2   73       0          3               1  17.795882        0   \n",
       "3   74       1          0               1  33.800817        1   \n",
       "4   89       0          0               0  20.716974        0   \n",
       "\n",
       "   AlcoholConsumption  PhysicalActivity  DietQuality  SleepQuality  ...  \\\n",
       "0           13.297218          6.327112     1.347214      9.025679  ...   \n",
       "1            4.542524          7.619885     0.518767      7.151293  ...   \n",
       "2           19.555085          7.844988     1.826335      9.673574  ...   \n",
       "3           12.209266          8.428001     7.435604      8.392554  ...   \n",
       "4           18.454356          6.310461     0.795498      5.597238  ...   \n",
       "\n",
       "   FunctionalAssessment  MemoryComplaints  BehavioralProblems       ADL  \\\n",
       "0              6.518877                 0                   0  1.725883   \n",
       "1              7.118696                 0                   0  2.592424   \n",
       "2              5.895077                 0                   0  7.119548   \n",
       "3              8.965106                 0                   1  6.481226   \n",
       "4              6.045039                 0                   0  0.014691   \n",
       "\n",
       "   Confusion  Disorientation  PersonalityChanges  DifficultyCompletingTasks  \\\n",
       "0          0               0                   0                          1   \n",
       "1          0               0                   0                          0   \n",
       "2          0               1                   0                          1   \n",
       "3          0               0                   0                          0   \n",
       "4          0               0                   1                          1   \n",
       "\n",
       "   Forgetfulness  Diagnosis  \n",
       "0              0          0  \n",
       "1              1          0  \n",
       "2              0          0  \n",
       "3              0          0  \n",
       "4              0          0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(['PatientID', 'DoctorInCharge'], axis=1, inplace=True)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1818b09c-3bb6-49db-8626-592d7bb1daae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Dataset After One-Hot Encoding:\n",
      "   Age  Gender        BMI  Smoking  AlcoholConsumption  PhysicalActivity  \\\n",
      "0   73       0  22.927749        0           13.297218          6.327112   \n",
      "1   89       0  26.827681        0            4.542524          7.619885   \n",
      "2   73       0  17.795882        0           19.555085          7.844988   \n",
      "3   74       1  33.800817        1           12.209266          8.428001   \n",
      "4   89       0  20.716974        0           18.454356          6.310461   \n",
      "\n",
      "   DietQuality  SleepQuality  FamilyHistoryAlzheimers  CardiovascularDisease  \\\n",
      "0     1.347214      9.025679                        0                      0   \n",
      "1     0.518767      7.151293                        0                      0   \n",
      "2     1.826335      9.673574                        1                      0   \n",
      "3     7.435604      8.392554                        0                      0   \n",
      "4     0.795498      5.597238                        0                      0   \n",
      "\n",
      "   ...  Forgetfulness  Diagnosis  Ethnicity_0  Ethnicity_1  Ethnicity_2  \\\n",
      "0  ...              0          0          1.0          0.0          0.0   \n",
      "1  ...              1          0          1.0          0.0          0.0   \n",
      "2  ...              0          0          0.0          0.0          0.0   \n",
      "3  ...              0          0          1.0          0.0          0.0   \n",
      "4  ...              0          0          1.0          0.0          0.0   \n",
      "\n",
      "   Ethnicity_3  EducationLevel_0  EducationLevel_1  EducationLevel_2  \\\n",
      "0          0.0               0.0               0.0               1.0   \n",
      "1          0.0               1.0               0.0               0.0   \n",
      "2          1.0               0.0               1.0               0.0   \n",
      "3          0.0               0.0               1.0               0.0   \n",
      "4          0.0               1.0               0.0               0.0   \n",
      "\n",
      "   EducationLevel_3  \n",
      "0               0.0  \n",
      "1               0.0  \n",
      "2               0.0  \n",
      "3               0.0  \n",
      "4               0.0  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Step 1: Select the nominal categorical features\n",
    "nominal_features = ['Ethnicity', 'EducationLevel']\n",
    "\n",
    "# Step 2: Initialize One-Hot Encoder without dropping any category\n",
    "ohe = OneHotEncoder(drop=None, sparse_output=False)  # Keep all categories\n",
    "\n",
    "# Step 3: Fit and transform the categorical features\n",
    "encoded_features = ohe.fit_transform(data[nominal_features])\n",
    "\n",
    "# Step 4: Convert the encoded features into a DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=ohe.get_feature_names_out(nominal_features))\n",
    "\n",
    "# Step 5: Drop the original categorical columns and merge encoded features\n",
    "data = data.drop(columns=nominal_features).reset_index(drop=True)  # Drop original categorical columns\n",
    "data = pd.concat([data, encoded_df], axis=1)  # Merge encoded data\n",
    "\n",
    "# Step 6: Verify the transformed data\n",
    "print(\"Updated Dataset After One-Hot Encoding:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fcdd257-fe6c-4e47-82a6-57dc7193cf12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2149, 39)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a0943aa-13ab-4659-9e3b-307c5992c550",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'FunctionalAssessment', 'ADL', 'MemoryComplaints', 'MMSE', 'BehavioralProblems', 'SleepQuality',\n",
    "    'CholesterolHDL', 'Ethnicity_2', 'Hypertension', 'Ethnicity_1', 'CholesterolLDL', 'Diabetes',\n",
    "    'EducationLevel_3', 'BMI', 'Ethnicity_3', 'Disorientation', 'CholesterolTriglycerides',\n",
    "    'AlcoholConsumption', 'Forgetfulness', 'PersonalityChanges', 'Gender'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f83a797-b3f3-4523-a131-aa8897449086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_features = ['FunctionalAssessment', 'ADL', 'MemoryComplaints', 'MMSE', 'BehavioralProblems', 'SleepQuality', 'CholesterolHDL', 'CholesterolLDL', 'BMI', 'CholesterolTriglycerides', 'Age', 'PhysicalActivity', 'DietQuality', 'DiastolicBP', 'Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19e86c59-78ca-4701-abcf-4041b3517dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[selected_features]  \n",
    "y = data['Diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ccf4b70-d8b8-4ff7-a70d-cc2e9a62d400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2149, 21)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "041df1fb-9f06-420f-9baf-a79b43476325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb0dabc5-1a53-49cf-8aea-00f4fd58f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data and transform both train and test separately\n",
    "X_train_scaled = scaler.fit_transform(X_train)  \n",
    "X_test_scaled = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8a744d-2ed1-4823-99c0-f78884074e9c",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c726f6d-e92c-4af3-bae1-4182bbe3c566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       277\n",
      "           1       0.88      0.83      0.86       153\n",
      "\n",
      "    accuracy                           0.90       430\n",
      "   macro avg       0.90      0.88      0.89       430\n",
      "weighted avg       0.90      0.90      0.90       430\n",
      "\n",
      "Confusion Matrix:\n",
      " [[260  17]\n",
      " [ 26 127]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt.fit(X_train_scaled, y_train)\n",
    "\n",
    "dt_y_pred = dt.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, dt_y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, dt_y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, dt_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a088435c-08cb-4e6c-bdd1-c7a67a4d908d",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd8212e4-496e-46e4-898d-1e3a9c586038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9418604651162791\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       277\n",
      "           1       0.96      0.87      0.91       153\n",
      "\n",
      "    accuracy                           0.94       430\n",
      "   macro avg       0.95      0.93      0.94       430\n",
      "weighted avg       0.94      0.94      0.94       430\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[272   5]\n",
      " [ 20 133]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=100)  # 100 trees in the forest\n",
    "\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "rf_y_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, rf_y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, rf_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2105eccc-37bf-4194-ad55-3ac38fb47f69",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ea569b3-5acd-4af2-8b01-bc0c7322e123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:07:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9465116279069767\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96       277\n",
      "           1       0.95      0.90      0.92       153\n",
      "\n",
      "    accuracy                           0.95       430\n",
      "   macro avg       0.95      0.94      0.94       430\n",
      "weighted avg       0.95      0.95      0.95       430\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[270   7]\n",
      " [ 16 137]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "xgb = XGBClassifier(random_state=42, n_estimators=100, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "xgb_y_pred = xgb.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, xgb_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, xgb_y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, xgb_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82cabf0-f6db-462a-a49e-269efe251eff",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7336bab7-c969-41d1-81f4-d6c218d76d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\chapp\\anaconda3\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: graphviz in c:\\users\\chapp\\anaconda3\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from catboost) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\chapp\\anaconda3\\lib\\site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from catboost) (1.14.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\chapp\\anaconda3\\lib\\site-packages (from catboost) (5.22.0)\n",
      "Requirement already satisfied: six in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chapp\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\chapp\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (3.2.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\chapp\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da4863f5-7145-44c5-98fd-3cc770893f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9558139534883721\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       277\n",
      "           1       0.96      0.92      0.94       153\n",
      "\n",
      "    accuracy                           0.96       430\n",
      "   macro avg       0.96      0.95      0.95       430\n",
      "weighted avg       0.96      0.96      0.96       430\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[271   6]\n",
      " [ 13 140]]\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "catboost = CatBoostClassifier(random_state=42, iterations=100, verbose=0)  # 100 iterations, silent training\n",
    "\n",
    "catboost.fit(X_train_scaled, y_train)\n",
    "\n",
    "catboost_y_pred = catboost.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, catboost_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, catboost_y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, catboost_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d038a79a-b893-4a53-9530-bd3c62039476",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3956d4c-4f57-45f1-87ce-19e6f96cafc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8976744186046511\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       277\n",
      "           1       0.88      0.83      0.85       153\n",
      "\n",
      "    accuracy                           0.90       430\n",
      "   macro avg       0.89      0.88      0.89       430\n",
      "weighted avg       0.90      0.90      0.90       430\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[259  18]\n",
      " [ 26 127]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "adaboost = AdaBoostClassifier(random_state=42, n_estimators=100)  # 100 weak learners\n",
    "\n",
    "adaboost.fit(X_train_scaled, y_train)\n",
    "\n",
    "adaboost_y_pred = adaboost.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, adaboost_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, adaboost_y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, adaboost_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2610c77-017c-420d-ab29-75c29fe154e0",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7ec624f-cade-47b4-a807-5c49ac181172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8534883720930233\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       277\n",
      "           1       0.83      0.74      0.78       153\n",
      "\n",
      "    accuracy                           0.85       430\n",
      "   macro avg       0.85      0.83      0.84       430\n",
      "weighted avg       0.85      0.85      0.85       430\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[254  23]\n",
      " [ 40 113]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize SVM Classifier\n",
    "svm = SVC(random_state=42, kernel='rbf')  # Using RBF kernel (default)\n",
    "\n",
    "# Train the model\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "svm_y_pred = svm.predict(X_test_scaled)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, svm_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, svm_y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, svm_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768dc570-7170-4065-b091-76de4cdc2dac",
   "metadata": {},
   "source": [
    "# Stratified cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eea95a-c1ae-4312-85a1-19ac80bfbcd3",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "772afb70-3fb5-48a6-ad61-34a9aedd65e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Accuracy: 0.924\n",
      "  Precision: 0.927\n",
      "  Recall: 0.924\n",
      "  F1-Score: 0.925\n",
      "\n",
      "Fold 2:\n",
      "  Accuracy: 0.884\n",
      "  Precision: 0.884\n",
      "  Recall: 0.884\n",
      "  F1-Score: 0.884\n",
      "\n",
      "Fold 3:\n",
      "  Accuracy: 0.866\n",
      "  Precision: 0.866\n",
      "  Recall: 0.866\n",
      "  F1-Score: 0.866\n",
      "\n",
      "Fold 4:\n",
      "  Accuracy: 0.890\n",
      "  Precision: 0.890\n",
      "  Recall: 0.890\n",
      "  F1-Score: 0.890\n",
      "\n",
      "Fold 5:\n",
      "  Accuracy: 0.913\n",
      "  Precision: 0.913\n",
      "  Recall: 0.913\n",
      "  F1-Score: 0.913\n",
      "\n",
      "Fold 6:\n",
      "  Accuracy: 0.872\n",
      "  Precision: 0.871\n",
      "  Recall: 0.872\n",
      "  F1-Score: 0.870\n",
      "\n",
      "Fold 7:\n",
      "  Accuracy: 0.890\n",
      "  Precision: 0.889\n",
      "  Recall: 0.890\n",
      "  F1-Score: 0.888\n",
      "\n",
      "Fold 8:\n",
      "  Accuracy: 0.866\n",
      "  Precision: 0.867\n",
      "  Recall: 0.866\n",
      "  F1-Score: 0.867\n",
      "\n",
      "Fold 9:\n",
      "  Accuracy: 0.930\n",
      "  Precision: 0.930\n",
      "  Recall: 0.930\n",
      "  F1-Score: 0.930\n",
      "\n",
      "Fold 10:\n",
      "  Accuracy: 0.901\n",
      "  Precision: 0.901\n",
      "  Recall: 0.901\n",
      "  F1-Score: 0.901\n",
      "\n",
      "\n",
      "Final Cross-Validation Results (Average Over 10 Folds):\n",
      "  Accuracy: 0.894 ± 0.022\n",
      "  Precision: 0.894 ± 0.022\n",
      "  Recall: 0.894 ± 0.022\n",
      "  F1-Score: 0.893 ± 0.022\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Decision Tree Classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Apply 10-Fold Stratified Cross-Validation\n",
    "stratified_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform 10-Fold Cross-Validation\n",
    "for fold, (train_idx, test_idx) in enumerate(stratified_cv.split(X_train_scaled, y_train), 1):\n",
    "    X_train_fold, X_test_fold = X_train_scaled[train_idx], X_train_scaled[test_idx]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    # Train model on current fold\n",
    "    dt.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold = dt.predict(X_test_fold)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    precision = precision_score(y_test_fold, y_pred_fold, average='weighted')  # Weighted for class imbalance\n",
    "    recall = recall_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "    f1 = f1_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "\n",
    "    # Store results\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    # Print metrics for current fold\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  F1-Score: {f1:.3f}\\n\")\n",
    "\n",
    "# Print average results across all folds\n",
    "print(\"\\nFinal Cross-Validation Results (Average Over 10 Folds):\")\n",
    "print(f\"  Accuracy: {np.mean(accuracy_scores):.3f} ± {np.std(accuracy_scores):.3f}\")\n",
    "print(f\"  Precision: {np.mean(precision_scores):.3f} ± {np.std(precision_scores):.3f}\")\n",
    "print(f\"  Recall: {np.mean(recall_scores):.3f} ± {np.std(recall_scores):.3f}\")\n",
    "print(f\"  F1-Score: {np.mean(f1_scores):.3f} ± {np.std(f1_scores):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99af779d-18c8-49d7-9f1e-41825166f447",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5266f0ea-fab6-4599-9bcd-097d14bb978b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Accuracy: 0.971\n",
      "  Precision: 0.971\n",
      "  Recall: 0.971\n",
      "  F1-Score: 0.971\n",
      "\n",
      "Fold 2:\n",
      "  Accuracy: 0.942\n",
      "  Precision: 0.942\n",
      "  Recall: 0.942\n",
      "  F1-Score: 0.941\n",
      "\n",
      "Fold 3:\n",
      "  Accuracy: 0.930\n",
      "  Precision: 0.930\n",
      "  Recall: 0.930\n",
      "  F1-Score: 0.930\n",
      "\n",
      "Fold 4:\n",
      "  Accuracy: 0.924\n",
      "  Precision: 0.924\n",
      "  Recall: 0.924\n",
      "  F1-Score: 0.924\n",
      "\n",
      "Fold 5:\n",
      "  Accuracy: 0.948\n",
      "  Precision: 0.948\n",
      "  Recall: 0.948\n",
      "  F1-Score: 0.947\n",
      "\n",
      "Fold 6:\n",
      "  Accuracy: 0.953\n",
      "  Precision: 0.955\n",
      "  Recall: 0.953\n",
      "  F1-Score: 0.953\n",
      "\n",
      "Fold 7:\n",
      "  Accuracy: 0.919\n",
      "  Precision: 0.920\n",
      "  Recall: 0.919\n",
      "  F1-Score: 0.917\n",
      "\n",
      "Fold 8:\n",
      "  Accuracy: 0.948\n",
      "  Precision: 0.948\n",
      "  Recall: 0.948\n",
      "  F1-Score: 0.947\n",
      "\n",
      "Fold 9:\n",
      "  Accuracy: 0.953\n",
      "  Precision: 0.954\n",
      "  Recall: 0.953\n",
      "  F1-Score: 0.953\n",
      "\n",
      "Fold 10:\n",
      "  Accuracy: 0.965\n",
      "  Precision: 0.965\n",
      "  Recall: 0.965\n",
      "  F1-Score: 0.965\n",
      "\n",
      "\n",
      "Final Cross-Validation Results (Average Over 10 Folds):\n",
      "  Accuracy: 0.945 ± 0.016\n",
      "  Precision: 0.946 ± 0.016\n",
      "  Recall: 0.945 ± 0.016\n",
      "  F1-Score: 0.945 ± 0.016\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=100)  # 100 trees in the forest\n",
    "\n",
    "# Apply 10-Fold Stratified Cross-Validation\n",
    "stratified_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform 10-Fold Cross-Validation\n",
    "for fold, (train_idx, test_idx) in enumerate(stratified_cv.split(X_train_scaled, y_train), 1):\n",
    "    X_train_fold, X_test_fold = X_train_scaled[train_idx], X_train_scaled[test_idx]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    # Train model on current fold\n",
    "    rf.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold = rf.predict(X_test_fold)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    precision = precision_score(y_test_fold, y_pred_fold, average='weighted')  # Weighted for class imbalance\n",
    "    recall = recall_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "    f1 = f1_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "\n",
    "    # Store results\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    # Print metrics for current fold\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  F1-Score: {f1:.3f}\\n\")\n",
    "\n",
    "# Print average results across all folds\n",
    "print(\"\\nFinal Cross-Validation Results (Average Over 10 Folds):\")\n",
    "print(f\"  Accuracy: {np.mean(accuracy_scores):.3f} ± {np.std(accuracy_scores):.3f}\")\n",
    "print(f\"  Precision: {np.mean(precision_scores):.3f} ± {np.std(precision_scores):.3f}\")\n",
    "print(f\"  Recall: {np.mean(recall_scores):.3f} ± {np.std(recall_scores):.3f}\")\n",
    "print(f\"  F1-Score: {np.mean(f1_scores):.3f} ± {np.std(f1_scores):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d21c57-b363-4944-bdb1-92c09b74caad",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c24d7d25-bcc6-46c7-a57a-58cf59416004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Accuracy: 0.971\n",
      "  Precision: 0.971\n",
      "  Recall: 0.971\n",
      "  F1-Score: 0.971\n",
      "\n",
      "Fold 2:\n",
      "  Accuracy: 0.948\n",
      "  Precision: 0.948\n",
      "  Recall: 0.948\n",
      "  F1-Score: 0.947\n",
      "\n",
      "Fold 3:\n",
      "  Accuracy: 0.930\n",
      "  Precision: 0.930\n",
      "  Recall: 0.930\n",
      "  F1-Score: 0.930\n",
      "\n",
      "Fold 4:\n",
      "  Accuracy: 0.936\n",
      "  Precision: 0.936\n",
      "  Recall: 0.936\n",
      "  F1-Score: 0.936\n",
      "\n",
      "Fold 5:\n",
      "  Accuracy: 0.953\n",
      "  Precision: 0.953\n",
      "  Recall: 0.953\n",
      "  F1-Score: 0.953\n",
      "\n",
      "Fold 6:\n",
      "  Accuracy: 0.953\n",
      "  Precision: 0.955\n",
      "  Recall: 0.953\n",
      "  F1-Score: 0.953\n",
      "\n",
      "Fold 7:\n",
      "  Accuracy: 0.936\n",
      "  Precision: 0.936\n",
      "  Recall: 0.936\n",
      "  F1-Score: 0.935\n",
      "\n",
      "Fold 8:\n",
      "  Accuracy: 0.948\n",
      "  Precision: 0.948\n",
      "  Recall: 0.948\n",
      "  F1-Score: 0.947\n",
      "\n",
      "Fold 9:\n",
      "  Accuracy: 0.971\n",
      "  Precision: 0.971\n",
      "  Recall: 0.971\n",
      "  F1-Score: 0.971\n",
      "\n",
      "Fold 10:\n",
      "  Accuracy: 0.977\n",
      "  Precision: 0.977\n",
      "  Recall: 0.977\n",
      "  F1-Score: 0.977\n",
      "\n",
      "\n",
      "Final Cross-Validation Results (Average Over 10 Folds):\n",
      "  Accuracy: 0.952 ± 0.015\n",
      "  Precision: 0.953 ± 0.015\n",
      "  Recall: 0.952 ± 0.015\n",
      "  F1-Score: 0.952 ± 0.015\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize CatBoost Classifier\n",
    "catboost = CatBoostClassifier(random_state=42, iterations=100, verbose=0)  # 100 iterations, silent training\n",
    "\n",
    "# Apply 10-Fold Stratified Cross-Validation\n",
    "stratified_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform 10-Fold Cross-Validation\n",
    "for fold, (train_idx, test_idx) in enumerate(stratified_cv.split(X_train_scaled, y_train), 1):\n",
    "    X_train_fold, X_test_fold = X_train_scaled[train_idx], X_train_scaled[test_idx]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    # Train model on current fold\n",
    "    catboost.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold = catboost.predict(X_test_fold)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    precision = precision_score(y_test_fold, y_pred_fold, average='weighted')  # Weighted for class imbalance\n",
    "    recall = recall_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "    f1 = f1_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "\n",
    "    # Store results\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    # Print metrics for current fold\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  F1-Score: {f1:.3f}\\n\")\n",
    "\n",
    "# Print average results across all folds\n",
    "print(\"\\nFinal Cross-Validation Results (Average Over 10 Folds):\")\n",
    "print(f\"  Accuracy: {np.mean(accuracy_scores):.3f} ± {np.std(accuracy_scores):.3f}\")\n",
    "print(f\"  Precision: {np.mean(precision_scores):.3f} ± {np.std(precision_scores):.3f}\")\n",
    "print(f\"  Recall: {np.mean(recall_scores):.3f} ± {np.std(recall_scores):.3f}\")\n",
    "print(f\"  F1-Score: {np.mean(f1_scores):.3f} ± {np.std(f1_scores):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d182bbd-fd53-4f5b-a7c2-ab8282a42569",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a98c72c9-dbba-442a-8751-58bad17f458c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:12:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Accuracy: 0.977\n",
      "  Precision: 0.977\n",
      "  Recall: 0.977\n",
      "  F1-Score: 0.977\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:12:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2:\n",
      "  Accuracy: 0.948\n",
      "  Precision: 0.948\n",
      "  Recall: 0.948\n",
      "  F1-Score: 0.947\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:12:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3:\n",
      "  Accuracy: 0.924\n",
      "  Precision: 0.924\n",
      "  Recall: 0.924\n",
      "  F1-Score: 0.924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:12:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4:\n",
      "  Accuracy: 0.942\n",
      "  Precision: 0.943\n",
      "  Recall: 0.942\n",
      "  F1-Score: 0.942\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:12:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5:\n",
      "  Accuracy: 0.953\n",
      "  Precision: 0.953\n",
      "  Recall: 0.953\n",
      "  F1-Score: 0.953\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:12:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6:\n",
      "  Accuracy: 0.953\n",
      "  Precision: 0.955\n",
      "  Recall: 0.953\n",
      "  F1-Score: 0.953\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:12:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7:\n",
      "  Accuracy: 0.924\n",
      "  Precision: 0.925\n",
      "  Recall: 0.924\n",
      "  F1-Score: 0.924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:12:07] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8:\n",
      "  Accuracy: 0.953\n",
      "  Precision: 0.954\n",
      "  Recall: 0.953\n",
      "  F1-Score: 0.953\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:12:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9:\n",
      "  Accuracy: 0.959\n",
      "  Precision: 0.960\n",
      "  Recall: 0.959\n",
      "  F1-Score: 0.959\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:12:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10:\n",
      "  Accuracy: 0.977\n",
      "  Precision: 0.977\n",
      "  Recall: 0.977\n",
      "  F1-Score: 0.977\n",
      "\n",
      "\n",
      "Final Cross-Validation Results (Average Over 10 Folds):\n",
      "  Accuracy: 0.951 ± 0.017\n",
      "  Precision: 0.951 ± 0.017\n",
      "  Recall: 0.951 ± 0.017\n",
      "  F1-Score: 0.951 ± 0.017\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize XGBoost Classifier\n",
    "xgb = XGBClassifier(random_state=42, n_estimators=100, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Apply 10-Fold Stratified Cross-Validation\n",
    "stratified_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform 10-Fold Cross-Validation\n",
    "for fold, (train_idx, test_idx) in enumerate(stratified_cv.split(X_train_scaled, y_train), 1):\n",
    "    X_train_fold, X_test_fold = X_train_scaled[train_idx], X_train_scaled[test_idx]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    # Train model on current fold\n",
    "    xgb.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold = xgb.predict(X_test_fold)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    precision = precision_score(y_test_fold, y_pred_fold, average='weighted')  # Weighted for class imbalance\n",
    "    recall = recall_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "    f1 = f1_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "\n",
    "    # Store results\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    # Print metrics for current fold\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  F1-Score: {f1:.3f}\\n\")\n",
    "\n",
    "# Print average results across all folds\n",
    "print(\"\\nFinal Cross-Validation Results (Average Over 10 Folds):\")\n",
    "print(f\"  Accuracy: {np.mean(accuracy_scores):.3f} ± {np.std(accuracy_scores):.3f}\")\n",
    "print(f\"  Precision: {np.mean(precision_scores):.3f} ± {np.std(precision_scores):.3f}\")\n",
    "print(f\"  Recall: {np.mean(recall_scores):.3f} ± {np.std(recall_scores):.3f}\")\n",
    "print(f\"  F1-Score: {np.mean(f1_scores):.3f} ± {np.std(f1_scores):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdad0702-6f31-45b1-bf0e-084f82fade35",
   "metadata": {},
   "source": [
    "## stacking on the top 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c9f3ae8-6f09-4dac-9ddc-cb5d94d606df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Stacking Classifier (Test Set)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       277\n",
      "           1       0.96      0.91      0.93       153\n",
      "\n",
      "    accuracy                           0.95       430\n",
      "   macro avg       0.95      0.94      0.95       430\n",
      "weighted avg       0.95      0.95      0.95       430\n",
      "\n",
      "[[271   6]\n",
      " [ 14 139]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# Create the individual classifiers\n",
    "rf = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "xgb = make_pipeline(StandardScaler(), XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss'))\n",
    "catboost = make_pipeline(StandardScaler(), CatBoostClassifier(iterations=100, verbose=0, random_state=42))\n",
    "\n",
    "# Create the stacking classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[('rf', rf), ('xgb', xgb), ('catboost', catboost)],  # Base models\n",
    "    final_estimator=RandomForestClassifier(n_estimators=100, random_state=42)  # Meta learner\n",
    ")\n",
    "\n",
    "\n",
    "# Perform cross-validation predictions\n",
    "stacking_preds = cross_val_predict(stacking_clf, X_train, y_train, cv=5)\n",
    "\n",
    "# Train the classifiers on the full training set\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "stacking_test_preds = stacking_clf.predict(X_test)\n",
    "\n",
    "# Function to print classification report\n",
    "def print_classification_report(y_true, y_pred, title):\n",
    "    print(f\"\\n{title}\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Print classification reports\n",
    "print_classification_report(y_test, stacking_test_preds, \"Classification Report for Stacking Classifier (Test Set)\")\n",
    "print(confusion_matrix(y_test, stacking_test_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378736b1-ec39-4f70-a09d-363d450ea800",
   "metadata": {},
   "source": [
    "# parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99e17a6-8f3b-4202-b5b8-fbf7790e6f67",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32b6616e-eb2c-41d1-b24f-f9da86559f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\ma\\core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Accuracy: 0.9511627906976744\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       277\n",
      "           1       0.96      0.90      0.93       153\n",
      "\n",
      "    accuracy                           0.95       430\n",
      "   macro avg       0.95      0.94      0.95       430\n",
      "weighted avg       0.95      0.95      0.95       430\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[272   5]\n",
      " [ 16 137]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of trees\n",
    "    'max_depth': [10, 20, None],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum samples required at a leaf node\n",
    "    'max_features': ['sqrt', 'log2'],  # Number of features to consider for best split\n",
    "    'bootstrap': [True, False]  # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform Grid Search with 5-Fold Cross-Validation\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit on training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train Random Forest with best parameters\n",
    "best_rf = RandomForestClassifier(**best_params, random_state=42)\n",
    "best_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_y_pred = best_rf.predict(X_test_scaled)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, rf_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, rf_y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, rf_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd42791c-45c9-4e41-a8c4-8910b775be56",
   "metadata": {},
   "source": [
    "### cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9770fe8-1132-4137-a55c-9938bb68265b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'iterations': [100, 200, 500],  # Number of boosting iterations\n",
    "    'learning_rate': [0.01, 0.05, 0.1],  # Step size shrinkage to prevent overfitting\n",
    "    'depth': [4, 6, 8, 10],  # Maximum depth of the trees\n",
    "    'l2_leaf_reg': [1, 3, 5, 7],  # L2 regularization to prevent overfitting\n",
    "    'border_count': [32, 64, 128],  # Number of bins used for numeric feature quantization\n",
    "}\n",
    "\n",
    "# Initialize the CatBoost model\n",
    "catboost = CatBoostClassifier(random_state=42, verbose=0)\n",
    "\n",
    "# Perform Grid Search with 5-Fold Cross-Validation\n",
    "grid_search = GridSearchCV(catboost, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit on training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train CatBoost with best parameters\n",
    "best_catboost = CatBoostClassifier(**best_params, random_state=42, verbose=0)\n",
    "best_catboost.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "catboost_y_pred = best_catboost.predict(X_test_scaled)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, catboost_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, catboost_y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, catboost_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e27286-271a-492c-ac0e-737ff56dbf73",
   "metadata": {},
   "source": [
    "## stacking after hyper parameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81682eb-6204-4587-8754-b5934feed10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Create the individual classifiers\n",
    "rf = make_pipeline(StandardScaler(), RandomForestClassifier(\n",
    "    bootstrap=False,  # Do not use bootstrap sampling\n",
    "    max_depth=None,  # No maximum depth (fully grown trees)\n",
    "    max_features='sqrt',  # Use square root of features for best splits\n",
    "    min_samples_leaf=1,  # Minimum 1 sample per leaf\n",
    "    min_samples_split=2,  # Minimum 2 samples to split a node\n",
    "    n_estimators=100,  # Number of trees in the forest\n",
    "    random_state=42  # Ensures reproducibility\n",
    "))\n",
    "catboost = make_pipeline(StandardScaler(), CatBoostClassifier(iterations=100, verbose=0, random_state=42))\n",
    "\n",
    "# Create the stacking classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[('rf', rf), ('xgb', xgb), ('catboost', catboost)],  # Base models\n",
    "    final_estimator=RandomForestClassifier(n_estimators=100, random_state=42)  # Meta learner\n",
    ")\n",
    "\n",
    "\n",
    "# Perform cross-validation predictions\n",
    "stacking_preds = cross_val_predict(stacking_clf, X_train, y_train, cv=5)\n",
    "\n",
    "# Train the classifiers on the full training set\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "stacking_test_preds = stacking_clf.predict(X_test)\n",
    "\n",
    "# Function to print classification report\n",
    "def print_classification_report(y_true, y_pred, title):\n",
    "    print(f\"\\n{title}\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Print classification reports\n",
    "print_classification_report(y_test, stacking_test_preds, \"Classification Report for Stacking Classifier (Test Set)\")\n",
    "print(confusion_matrix(y_test, stacking_test_preds))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
