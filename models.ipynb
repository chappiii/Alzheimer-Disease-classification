{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2242383-e62f-4981-babf-d9030f536364",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee76958b-883c-4995-bdd4-34842de8464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import resample\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import friedmanchisquare, rankdata\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d08750-091b-405d-8ed9-69e1d896f8b2",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9557af2e-d86e-4ddc-b724-e3b921a77aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data = pd.read_csv(\"alzheimers_disease_data.csv\")\n",
    "data.shape\n",
    "data.drop(['PatientID', 'DoctorInCharge'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c2fb431-e236-4044-94f3-adaaf69a9c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2149, 33)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef63cc35-e5ac-45ae-8a2a-4e4049d4ba90",
   "metadata": {},
   "source": [
    "# Balancing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1202edd-25d8-404c-b601-6c919c6d4175",
   "metadata": {},
   "source": [
    "- why balabcing\n",
    "- strugle in balancing and selecting under sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1360418-ec8f-4993-a441-1f24b43c5670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class Distribution:\n",
      " Diagnosis\n",
      "0    64.634714\n",
      "1    35.365286\n",
      "Name: proportion, dtype: float64\n",
      "Balanced Class Distribution:\n",
      " Diagnosis\n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_counts = data.iloc[:, -1].value_counts(normalize=True) * 100\n",
    "print(\"Original Class Distribution:\\n\", class_counts)\n",
    "\n",
    "# Splitting features and target variable\n",
    "X = data.iloc[:, :-1]  # Features\n",
    "y = data.iloc[:, -1]   # Target\n",
    "\n",
    "# Separate majority and minority classes\n",
    "majority_class = data[y == 0]  # Non-Alzheimer's (64.6%)\n",
    "minority_class = data[y == 1]  # Alzheimer's (35.4%)\n",
    "\n",
    "# Undersample the majority class to match the minority class size\n",
    "majority_downsampled = resample(majority_class, \n",
    "                                replace=False,  # Without replacement\n",
    "                                n_samples=len(minority_class),  # Match minority class size\n",
    "                                random_state=42)\n",
    "\n",
    "# Combine the downsampled majority class with the original minority class\n",
    "balanced_data = pd.concat([majority_downsampled, minority_class])\n",
    "\n",
    "# Shuffle the dataset\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check new class distribution\n",
    "new_class_counts = balanced_data.iloc[:, -1].value_counts(normalize=True) * 100\n",
    "print(\"Balanced Class Distribution:\\n\", new_class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be64a91b-4753-4b78-bac2-54e499756d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1520, 33)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b94889-875e-45fa-847a-dc1b01cae316",
   "metadata": {},
   "source": [
    "# Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1818b09c-3bb6-49db-8626-592d7bb1daae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Dataset After One-Hot Encoding:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholConsumption</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>DietQuality</th>\n",
       "      <th>SleepQuality</th>\n",
       "      <th>FamilyHistoryAlzheimers</th>\n",
       "      <th>CardiovascularDisease</th>\n",
       "      <th>...</th>\n",
       "      <th>Forgetfulness</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Ethnicity_0</th>\n",
       "      <th>Ethnicity_1</th>\n",
       "      <th>Ethnicity_2</th>\n",
       "      <th>Ethnicity_3</th>\n",
       "      <th>EducationLevel_0</th>\n",
       "      <th>EducationLevel_1</th>\n",
       "      <th>EducationLevel_2</th>\n",
       "      <th>EducationLevel_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>16.834968</td>\n",
       "      <td>0</td>\n",
       "      <td>19.053565</td>\n",
       "      <td>4.352272</td>\n",
       "      <td>3.432055</td>\n",
       "      <td>7.361459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>35.353244</td>\n",
       "      <td>1</td>\n",
       "      <td>0.768943</td>\n",
       "      <td>8.883326</td>\n",
       "      <td>4.085773</td>\n",
       "      <td>7.450835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>32.726550</td>\n",
       "      <td>0</td>\n",
       "      <td>16.971929</td>\n",
       "      <td>8.569751</td>\n",
       "      <td>8.744619</td>\n",
       "      <td>9.227229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>38.668960</td>\n",
       "      <td>1</td>\n",
       "      <td>6.669039</td>\n",
       "      <td>7.328895</td>\n",
       "      <td>7.973275</td>\n",
       "      <td>9.966551</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>30.646711</td>\n",
       "      <td>0</td>\n",
       "      <td>4.452856</td>\n",
       "      <td>0.768016</td>\n",
       "      <td>4.978013</td>\n",
       "      <td>7.715735</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender        BMI  Smoking  AlcoholConsumption  PhysicalActivity  \\\n",
       "0   80       1  16.834968        0           19.053565          4.352272   \n",
       "1   88       1  35.353244        1            0.768943          8.883326   \n",
       "2   63       0  32.726550        0           16.971929          8.569751   \n",
       "3   75       1  38.668960        1            6.669039          7.328895   \n",
       "4   72       0  30.646711        0            4.452856          0.768016   \n",
       "\n",
       "   DietQuality  SleepQuality  FamilyHistoryAlzheimers  CardiovascularDisease  \\\n",
       "0     3.432055      7.361459                        0                      0   \n",
       "1     4.085773      7.450835                        0                      0   \n",
       "2     8.744619      9.227229                        0                      0   \n",
       "3     7.973275      9.966551                        0                      0   \n",
       "4     4.978013      7.715735                        0                      1   \n",
       "\n",
       "   ...  Forgetfulness  Diagnosis  Ethnicity_0  Ethnicity_1  Ethnicity_2  \\\n",
       "0  ...              0          0          0.0          1.0          0.0   \n",
       "1  ...              1          1          1.0          0.0          0.0   \n",
       "2  ...              0          1          0.0          0.0          1.0   \n",
       "3  ...              1          0          0.0          0.0          0.0   \n",
       "4  ...              0          0          0.0          1.0          0.0   \n",
       "\n",
       "   Ethnicity_3  EducationLevel_0  EducationLevel_1  EducationLevel_2  \\\n",
       "0          0.0               0.0               1.0               0.0   \n",
       "1          0.0               0.0               1.0               0.0   \n",
       "2          0.0               0.0               1.0               0.0   \n",
       "3          1.0               0.0               0.0               1.0   \n",
       "4          0.0               0.0               0.0               1.0   \n",
       "\n",
       "   EducationLevel_3  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Select the nominal categorical features\n",
    "nominal_features = ['Ethnicity', 'EducationLevel']\n",
    "\n",
    "# Step 2: Initialize One-Hot Encoder without dropping any category\n",
    "ohe = OneHotEncoder(drop=None, sparse_output=False)  # Keep all categories\n",
    "\n",
    "# Step 3: Fit and transform the categorical features\n",
    "encoded_features = ohe.fit_transform(balanced_data[nominal_features])\n",
    "\n",
    "# Step 4: Convert the encoded features into a DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=ohe.get_feature_names_out(nominal_features))\n",
    "\n",
    "# Step 5: Drop the original categorical columns and merge encoded features\n",
    "data = balanced_data.drop(columns=nominal_features).reset_index(drop=True)  # Drop original categorical columns\n",
    "data = pd.concat([data, encoded_df], axis=1)  # Merge encoded data\n",
    "\n",
    "# Step 6: Verify the transformed data\n",
    "print(\"Updated Dataset After One-Hot Encoding:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fcdd257-fe6c-4e47-82a6-57dc7193cf12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1520, 39)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7a0943aa-13ab-4659-9e3b-307c5992c550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_features = [\n",
    "#     'FunctionalAssessment', 'ADL', 'MemoryComplaints', 'MMSE', 'BehavioralProblems', 'SleepQuality'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f83a797-b3f3-4523-a131-aa8897449086",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['FunctionalAssessment', 'ADL', 'MemoryComplaints', 'MMSE', 'BehavioralProblems', 'SleepQuality', 'CholesterolHDL', 'CholesterolLDL', 'BMI', 'CholesterolTriglycerides', 'Age', 'PhysicalActivity', 'DietQuality', 'DiastolicBP', 'Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6017ab5c-98f0-456c-8dd7-746e4aa06d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19e86c59-78ca-4701-abcf-4041b3517dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[selected_features]  \n",
    "y = data['Diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ccf4b70-d8b8-4ff7-a70d-cc2e9a62d400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1520, 39)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3454bf07-4291-4d1a-9c13-de053579cc67",
   "metadata": {},
   "source": [
    "# split after feature selection and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "041df1fb-9f06-420f-9baf-a79b43476325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb0dabc5-1a53-49cf-8aea-00f4fd58f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data and transform both train and test separately\n",
    "X_train_scaled = scaler.fit_transform(X_train)  \n",
    "X_test_scaled = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8738369e-9c19-404c-8aba-a217e4f5b38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'combined_data.csv'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data = X.copy()\n",
    "combined_data['Diagnosis'] = y\n",
    "\n",
    "# Save to CSV file\n",
    "combined_csv_path = \"combined_data.csv\"\n",
    "combined_data.to_csv(combined_csv_path, index=False)\n",
    "\n",
    "# Provide download link\n",
    "combined_csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58c5f97a-047f-4a80-b1ed-ccf1941f876f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionalAssessment        0\n",
       "ADL                         0\n",
       "MemoryComplaints            0\n",
       "MMSE                        0\n",
       "BehavioralProblems          0\n",
       "SleepQuality                0\n",
       "CholesterolHDL              0\n",
       "CholesterolLDL              0\n",
       "BMI                         0\n",
       "CholesterolTriglycerides    0\n",
       "Age                         0\n",
       "PhysicalActivity            0\n",
       "DietQuality                 0\n",
       "DiastolicBP                 0\n",
       "Gender                      0\n",
       "Diagnosis                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata = pd.read_csv(\"combined_data.csv\")\n",
    "\n",
    "# Check for missing or NaN values\n",
    "missing_values = newdata.isnull().sum()\n",
    "\n",
    "# Display missing values\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd6637-d3a6-4b75-a322-ca29bbf9243b",
   "metadata": {},
   "source": [
    "# Fit and Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8a744d-2ed1-4823-99c0-f78884074e9c",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c726f6d-e92c-4af3-bae1-4182bbe3c566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.881578947368421\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.881     0.881     0.881       151\n",
      "           1      0.882     0.882     0.882       153\n",
      "\n",
      "    accuracy                          0.882       304\n",
      "   macro avg      0.882     0.882     0.882       304\n",
      "weighted avg      0.882     0.882     0.882       304\n",
      "\n",
      "Confusion Matrix:\n",
      " [[133  18]\n",
      " [ 18 135]]\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt.fit(X_train_scaled, y_train)\n",
    "\n",
    "dt_y_pred = dt.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, dt_y_pred))\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, dt_y_pred, digits=3))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, dt_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a088435c-08cb-4e6c-bdd1-c7a67a4d908d",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd8212e4-496e-46e4-898d-1e3a9c586038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9342105263157895\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.912     0.960     0.935       151\n",
      "           1      0.959     0.908     0.933       153\n",
      "\n",
      "    accuracy                          0.934       304\n",
      "   macro avg      0.935     0.934     0.934       304\n",
      "weighted avg      0.935     0.934     0.934       304\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[145   6]\n",
      " [ 14 139]]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42, n_estimators=100)  # 100 trees in the forest\n",
    "\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "rf_y_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, rf_y_pred, digits=3))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, rf_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2105eccc-37bf-4194-ad55-3ac38fb47f69",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ea569b3-5acd-4af2-8b01-bc0c7322e123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9243421052631579\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.916     0.934     0.925       151\n",
      "           1      0.933     0.915     0.924       153\n",
      "\n",
      "    accuracy                          0.924       304\n",
      "   macro avg      0.924     0.924     0.924       304\n",
      "weighted avg      0.925     0.924     0.924       304\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[141  10]\n",
      " [ 13 140]]\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state=42, n_estimators=100, eval_metric='logloss')\n",
    "\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "xgb_y_pred = xgb.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, xgb_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, xgb_y_pred, digits=3))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, xgb_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82cabf0-f6db-462a-a49e-269efe251eff",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7336bab7-c969-41d1-81f4-d6c218d76d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\chapp\\anaconda3\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: graphviz in c:\\users\\chapp\\anaconda3\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from catboost) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\chapp\\anaconda3\\lib\\site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from catboost) (1.14.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\chapp\\anaconda3\\lib\\site-packages (from catboost) (5.22.0)\n",
      "Requirement already satisfied: six in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chapp\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\chapp\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\chapp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (3.2.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\chapp\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da4863f5-7145-44c5-98fd-3cc770893f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9375\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.923     0.954     0.938       151\n",
      "           1      0.953     0.922     0.937       153\n",
      "\n",
      "    accuracy                          0.938       304\n",
      "   macro avg      0.938     0.938     0.937       304\n",
      "weighted avg      0.938     0.938     0.937       304\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[144   7]\n",
      " [ 12 141]]\n"
     ]
    }
   ],
   "source": [
    "catboost = CatBoostClassifier(random_state=42, iterations=100, verbose=0)  # 100 iterations, silent training\n",
    "\n",
    "catboost.fit(X_train_scaled, y_train)\n",
    "\n",
    "catboost_y_pred = catboost.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, catboost_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, catboost_y_pred, digits=3))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, catboost_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d038a79a-b893-4a53-9530-bd3c62039476",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3956d4c-4f57-45f1-87ce-19e6f96cafc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8848684210526315\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.939     0.821     0.876       151\n",
      "           1      0.843     0.948     0.892       153\n",
      "\n",
      "    accuracy                          0.885       304\n",
      "   macro avg      0.891     0.884     0.884       304\n",
      "weighted avg      0.891     0.885     0.884       304\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[124  27]\n",
      " [  8 145]]\n"
     ]
    }
   ],
   "source": [
    "adaboost = AdaBoostClassifier(random_state=42, n_estimators=100)  # 100 weak learners\n",
    "\n",
    "adaboost.fit(X_train_scaled, y_train)\n",
    "\n",
    "adaboost_y_pred = adaboost.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, adaboost_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, adaboost_y_pred, digits=3))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, adaboost_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2610c77-017c-420d-ab29-75c29fe154e0",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d7ec624f-cade-47b4-a807-5c49ac181172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.875\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.865     0.887     0.876       151\n",
      "           1      0.886     0.863     0.874       153\n",
      "\n",
      "    accuracy                          0.875       304\n",
      "   macro avg      0.875     0.875     0.875       304\n",
      "weighted avg      0.875     0.875     0.875       304\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[134  17]\n",
      " [ 21 132]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize SVM Classifier\n",
    "svm = SVC(random_state=42, kernel='rbf')  # Using RBF kernel (default)\n",
    "\n",
    "# Train the model\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "svm_y_pred = svm.predict(X_test_scaled)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, svm_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, svm_y_pred, digits=3))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, svm_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768dc570-7170-4065-b091-76de4cdc2dac",
   "metadata": {},
   "source": [
    "# Stratified cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99af779d-18c8-49d7-9f1e-41825166f447",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5266f0ea-fab6-4599-9bcd-097d14bb978b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Accuracy: 0.951\n",
      "  Precision: 0.955\n",
      "  Recall: 0.951\n",
      "  F1-Score: 0.951\n",
      "\n",
      "Fold 2:\n",
      "  Accuracy: 0.926\n",
      "  Precision: 0.926\n",
      "  Recall: 0.926\n",
      "  F1-Score: 0.926\n",
      "\n",
      "Fold 3:\n",
      "  Accuracy: 0.934\n",
      "  Precision: 0.934\n",
      "  Recall: 0.934\n",
      "  F1-Score: 0.934\n",
      "\n",
      "Fold 4:\n",
      "  Accuracy: 0.967\n",
      "  Precision: 0.969\n",
      "  Recall: 0.967\n",
      "  F1-Score: 0.967\n",
      "\n",
      "Fold 5:\n",
      "  Accuracy: 0.959\n",
      "  Precision: 0.960\n",
      "  Recall: 0.959\n",
      "  F1-Score: 0.959\n",
      "\n",
      "Fold 6:\n",
      "  Accuracy: 0.918\n",
      "  Precision: 0.918\n",
      "  Recall: 0.918\n",
      "  F1-Score: 0.918\n",
      "\n",
      "Fold 7:\n",
      "  Accuracy: 0.926\n",
      "  Precision: 0.931\n",
      "  Recall: 0.926\n",
      "  F1-Score: 0.925\n",
      "\n",
      "Fold 8:\n",
      "  Accuracy: 0.950\n",
      "  Precision: 0.951\n",
      "  Recall: 0.950\n",
      "  F1-Score: 0.950\n",
      "\n",
      "Fold 9:\n",
      "  Accuracy: 0.926\n",
      "  Precision: 0.931\n",
      "  Recall: 0.926\n",
      "  F1-Score: 0.925\n",
      "\n",
      "Fold 10:\n",
      "  Accuracy: 0.942\n",
      "  Precision: 0.942\n",
      "  Recall: 0.942\n",
      "  F1-Score: 0.942\n",
      "\n",
      "\n",
      "Final Cross-Validation Results for RF (Average Over 10 Folds):\n",
      "  Accuracy: 0.940 ± 0.016\n",
      "  Precision: 0.942 ± 0.016\n",
      "  Recall: 0.940 ± 0.016\n",
      "  F1-Score: 0.940 ± 0.016\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=100)  # 100 trees in the forest\n",
    "\n",
    "# Apply 10-Fold Stratified Cross-Validation\n",
    "stratified_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform 10-Fold Cross-Validation\n",
    "for fold, (train_idx, test_idx) in enumerate(stratified_cv.split(X_train_scaled, y_train), 1):\n",
    "    X_train_fold, X_test_fold = X_train_scaled[train_idx], X_train_scaled[test_idx]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    # Train model on current fold\n",
    "    rf.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold = rf.predict(X_test_fold)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    precision = precision_score(y_test_fold, y_pred_fold, average='weighted')  # Weighted for class imbalance\n",
    "    recall = recall_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "    f1 = f1_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "\n",
    "    # Store results\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    # Print metrics for current fold\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  F1-Score: {f1:.3f}\\n\")\n",
    "\n",
    "# Print average results across all folds\n",
    "print(\"\\nFinal Cross-Validation Results for RF (Average Over 10 Folds):\")\n",
    "print(f\"  Accuracy: {np.mean(accuracy_scores):.3f} ± {np.std(accuracy_scores):.3f}\")\n",
    "print(f\"  Precision: {np.mean(precision_scores):.3f} ± {np.std(precision_scores):.3f}\")\n",
    "print(f\"  Recall: {np.mean(recall_scores):.3f} ± {np.std(recall_scores):.3f}\")\n",
    "print(f\"  F1-Score: {np.mean(f1_scores):.3f} ± {np.std(f1_scores):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d21c57-b363-4944-bdb1-92c09b74caad",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c24d7d25-bcc6-46c7-a57a-58cf59416004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Accuracy: 0.951\n",
      "  Precision: 0.955\n",
      "  Recall: 0.951\n",
      "  F1-Score: 0.951\n",
      "\n",
      "Fold 2:\n",
      "  Accuracy: 0.926\n",
      "  Precision: 0.926\n",
      "  Recall: 0.926\n",
      "  F1-Score: 0.926\n",
      "\n",
      "Fold 3:\n",
      "  Accuracy: 0.943\n",
      "  Precision: 0.943\n",
      "  Recall: 0.943\n",
      "  F1-Score: 0.943\n",
      "\n",
      "Fold 4:\n",
      "  Accuracy: 0.975\n",
      "  Precision: 0.977\n",
      "  Recall: 0.975\n",
      "  F1-Score: 0.975\n",
      "\n",
      "Fold 5:\n",
      "  Accuracy: 0.967\n",
      "  Precision: 0.968\n",
      "  Recall: 0.967\n",
      "  F1-Score: 0.967\n",
      "\n",
      "Fold 6:\n",
      "  Accuracy: 0.951\n",
      "  Precision: 0.951\n",
      "  Recall: 0.951\n",
      "  F1-Score: 0.951\n",
      "\n",
      "Fold 7:\n",
      "  Accuracy: 0.926\n",
      "  Precision: 0.928\n",
      "  Recall: 0.926\n",
      "  F1-Score: 0.925\n",
      "\n",
      "Fold 8:\n",
      "  Accuracy: 0.950\n",
      "  Precision: 0.951\n",
      "  Recall: 0.950\n",
      "  F1-Score: 0.950\n",
      "\n",
      "Fold 9:\n",
      "  Accuracy: 0.917\n",
      "  Precision: 0.921\n",
      "  Recall: 0.917\n",
      "  F1-Score: 0.917\n",
      "\n",
      "Fold 10:\n",
      "  Accuracy: 0.959\n",
      "  Precision: 0.960\n",
      "  Recall: 0.959\n",
      "  F1-Score: 0.959\n",
      "\n",
      "\n",
      "Final Cross-Validation Results for catboost (Average Over 10 Folds):\n",
      "  Accuracy: 0.947 ± 0.018\n",
      "  Precision: 0.948 ± 0.017\n",
      "  Recall: 0.947 ± 0.018\n",
      "  F1-Score: 0.946 ± 0.018\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize CatBoost Classifier\n",
    "catboost = CatBoostClassifier(random_state=42, iterations=100, verbose=0)  # 100 iterations, silent training\n",
    "\n",
    "# Apply 10-Fold Stratified Cross-Validation\n",
    "stratified_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform 10-Fold Cross-Validation\n",
    "for fold, (train_idx, test_idx) in enumerate(stratified_cv.split(X_train_scaled, y_train), 1):\n",
    "    X_train_fold, X_test_fold = X_train_scaled[train_idx], X_train_scaled[test_idx]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    # Train model on current fold\n",
    "    catboost.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold = catboost.predict(X_test_fold)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    precision = precision_score(y_test_fold, y_pred_fold, average='weighted')  # Weighted for class imbalance\n",
    "    recall = recall_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "    f1 = f1_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "\n",
    "    # Store results\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    # Print metrics for current fold\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  F1-Score: {f1:.3f}\\n\")\n",
    "\n",
    "# Print average results across all folds\n",
    "print(\"\\nFinal Cross-Validation Results for catboost (Average Over 10 Folds):\")\n",
    "print(f\"  Accuracy: {np.mean(accuracy_scores):.3f} ± {np.std(accuracy_scores):.3f}\")\n",
    "print(f\"  Precision: {np.mean(precision_scores):.3f} ± {np.std(precision_scores):.3f}\")\n",
    "print(f\"  Recall: {np.mean(recall_scores):.3f} ± {np.std(recall_scores):.3f}\")\n",
    "print(f\"  F1-Score: {np.mean(f1_scores):.3f} ± {np.std(f1_scores):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d182bbd-fd53-4f5b-a7c2-ab8282a42569",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a98c72c9-dbba-442a-8751-58bad17f458c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Accuracy: 0.943\n",
      "  Precision: 0.946\n",
      "  Recall: 0.943\n",
      "  F1-Score: 0.943\n",
      "\n",
      "Fold 2:\n",
      "  Accuracy: 0.943\n",
      "  Precision: 0.943\n",
      "  Recall: 0.943\n",
      "  F1-Score: 0.943\n",
      "\n",
      "Fold 3:\n",
      "  Accuracy: 0.943\n",
      "  Precision: 0.943\n",
      "  Recall: 0.943\n",
      "  F1-Score: 0.943\n",
      "\n",
      "Fold 4:\n",
      "  Accuracy: 0.975\n",
      "  Precision: 0.977\n",
      "  Recall: 0.975\n",
      "  F1-Score: 0.975\n",
      "\n",
      "Fold 5:\n",
      "  Accuracy: 0.959\n",
      "  Precision: 0.960\n",
      "  Recall: 0.959\n",
      "  F1-Score: 0.959\n",
      "\n",
      "Fold 6:\n",
      "  Accuracy: 0.926\n",
      "  Precision: 0.929\n",
      "  Recall: 0.926\n",
      "  F1-Score: 0.926\n",
      "\n",
      "Fold 7:\n",
      "  Accuracy: 0.917\n",
      "  Precision: 0.921\n",
      "  Recall: 0.917\n",
      "  F1-Score: 0.917\n",
      "\n",
      "Fold 8:\n",
      "  Accuracy: 0.950\n",
      "  Precision: 0.951\n",
      "  Recall: 0.950\n",
      "  F1-Score: 0.950\n",
      "\n",
      "Fold 9:\n",
      "  Accuracy: 0.909\n",
      "  Precision: 0.918\n",
      "  Recall: 0.909\n",
      "  F1-Score: 0.909\n",
      "\n",
      "Fold 10:\n",
      "  Accuracy: 0.926\n",
      "  Precision: 0.926\n",
      "  Recall: 0.926\n",
      "  F1-Score: 0.926\n",
      "\n",
      "\n",
      "Final Cross-Validation Results for XGboost (Average Over 10 Folds):\n",
      "  Accuracy: 0.939 ± 0.019\n",
      "  Precision: 0.941 ± 0.017\n",
      "  Recall: 0.939 ± 0.019\n",
      "  F1-Score: 0.939 ± 0.019\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize XGBoost Classifier\n",
    "xgb = XGBClassifier(random_state=42, n_estimators=100, eval_metric='logloss')\n",
    "\n",
    "# Apply 10-Fold Stratified Cross-Validation\n",
    "stratified_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform 10-Fold Cross-Validation\n",
    "for fold, (train_idx, test_idx) in enumerate(stratified_cv.split(X_train_scaled, y_train), 1):\n",
    "    X_train_fold, X_test_fold = X_train_scaled[train_idx], X_train_scaled[test_idx]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    # Train model on current fold\n",
    "    xgb.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold = xgb.predict(X_test_fold)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    precision = precision_score(y_test_fold, y_pred_fold, average='weighted')  # Weighted for class imbalance\n",
    "    recall = recall_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "    f1 = f1_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "\n",
    "    # Store results\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    # Print metrics for current fold\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  F1-Score: {f1:.3f}\\n\")\n",
    "\n",
    "# Print average results across all folds\n",
    "print(\"\\nFinal Cross-Validation Results for XGboost (Average Over 10 Folds):\")\n",
    "print(f\"  Accuracy: {np.mean(accuracy_scores):.3f} ± {np.std(accuracy_scores):.3f}\")\n",
    "print(f\"  Precision: {np.mean(precision_scores):.3f} ± {np.std(precision_scores):.3f}\")\n",
    "print(f\"  Recall: {np.mean(recall_scores):.3f} ± {np.std(recall_scores):.3f}\")\n",
    "print(f\"  F1-Score: {np.mean(f1_scores):.3f} ± {np.std(f1_scores):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378736b1-ec39-4f70-a09d-363d450ea800",
   "metadata": {},
   "source": [
    "# parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99e17a6-8f3b-4202-b5b8-fbf7790e6f67",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32b6616e-eb2c-41d1-b24f-f9da86559f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "Best Hyperparameters: {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "\n",
      "Accuracy: 0.9375\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.923     0.954     0.938       151\n",
      "           1      0.953     0.922     0.937       153\n",
      "\n",
      "    accuracy                          0.938       304\n",
      "   macro avg      0.938     0.938     0.937       304\n",
      "weighted avg      0.938     0.938     0.937       304\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[144   7]\n",
      " [ 12 141]]\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of each tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be a leaf node\n",
    "    'max_features': ['sqrt', 'log2'],  # Number of features to consider for best split\n",
    "    'bootstrap': [True, False],  # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform Grid Search with 5-Fold Cross-Validation\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit on training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train Random Forest with best parameters\n",
    "best_rf = RandomForestClassifier(**best_params, random_state=42)\n",
    "best_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_y_pred = best_rf.predict(X_test_scaled)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, rf_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, rf_y_pred, digits=3))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, rf_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd42791c-45c9-4e41-a8c4-8910b775be56",
   "metadata": {},
   "source": [
    "### cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e9770fe8-1132-4137-a55c-9938bb68265b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "Best Hyperparameters: {'border_count': 128, 'depth': 4, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.01, 'loss_function': 'Logloss'}\n",
      "\n",
      "Accuracy: 0.9407894736842105\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.929     0.954     0.941       151\n",
      "           1      0.953     0.928     0.940       153\n",
      "\n",
      "    accuracy                          0.941       304\n",
      "   macro avg      0.941     0.941     0.941       304\n",
      "weighted avg      0.941     0.941     0.941       304\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[144   7]\n",
      " [ 11 142]]\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'iterations': [500, 1000, 1500],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'depth': [4, 6, 8],\n",
    "    'l2_leaf_reg': [1, 3, 5],\n",
    "    'border_count': [32, 64, 128],\n",
    "    'loss_function': ['Logloss']\n",
    "}\n",
    "\n",
    "# Initialize the CatBoost model\n",
    "catboost = CatBoostClassifier(random_state=42, verbose=0)\n",
    "\n",
    "# Perform Grid Search with 5-Fold Cross-Validation\n",
    "grid_search = GridSearchCV(catboost, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit on training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train CatBoost with best parameters\n",
    "best_catboost = CatBoostClassifier(**best_params, random_state=42, verbose=0)\n",
    "best_catboost.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "catboost_y_pred = best_catboost.predict(X_test_scaled)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, catboost_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, catboost_y_pred, digits=3))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, catboost_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9677a00-563f-4820-bdf9-a635041e1320",
   "metadata": {},
   "source": [
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8d98dc60-380a-4ae6-bf49-34f4b2d4b35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:34:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5785310\ttotal: 4.73ms\tremaining: 4.72s\n",
      "100:\tlearn: 0.1071573\ttotal: 455ms\tremaining: 4.05s\n",
      "200:\tlearn: 0.0650612\ttotal: 849ms\tremaining: 3.38s\n",
      "300:\tlearn: 0.0431047\ttotal: 1.27s\tremaining: 2.96s\n",
      "400:\tlearn: 0.0304908\ttotal: 1.7s\tremaining: 2.54s\n",
      "500:\tlearn: 0.0226870\ttotal: 2.15s\tremaining: 2.14s\n",
      "600:\tlearn: 0.0177688\ttotal: 2.59s\tremaining: 1.72s\n",
      "700:\tlearn: 0.0144000\ttotal: 3.05s\tremaining: 1.3s\n",
      "800:\tlearn: 0.0122343\ttotal: 3.49s\tremaining: 867ms\n",
      "900:\tlearn: 0.0104172\ttotal: 3.94s\tremaining: 433ms\n",
      "999:\tlearn: 0.0093536\ttotal: 4.37s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:34:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5733256\ttotal: 5.31ms\tremaining: 5.31s\n",
      "100:\tlearn: 0.0982809\ttotal: 464ms\tremaining: 4.13s\n",
      "200:\tlearn: 0.0584185\ttotal: 921ms\tremaining: 3.66s\n",
      "300:\tlearn: 0.0366199\ttotal: 1.36s\tremaining: 3.17s\n",
      "400:\tlearn: 0.0244561\ttotal: 1.8s\tremaining: 2.69s\n",
      "500:\tlearn: 0.0183659\ttotal: 2.21s\tremaining: 2.2s\n",
      "600:\tlearn: 0.0142048\ttotal: 2.62s\tremaining: 1.74s\n",
      "700:\tlearn: 0.0116738\ttotal: 2.98s\tremaining: 1.27s\n",
      "800:\tlearn: 0.0097143\ttotal: 3.37s\tremaining: 838ms\n",
      "900:\tlearn: 0.0087821\ttotal: 3.79s\tremaining: 416ms\n",
      "999:\tlearn: 0.0078476\ttotal: 4.19s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:34:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5780561\ttotal: 6.23ms\tremaining: 6.22s\n",
      "100:\tlearn: 0.1111752\ttotal: 395ms\tremaining: 3.52s\n",
      "200:\tlearn: 0.0672155\ttotal: 808ms\tremaining: 3.21s\n",
      "300:\tlearn: 0.0414508\ttotal: 1.25s\tremaining: 2.9s\n",
      "400:\tlearn: 0.0293439\ttotal: 1.7s\tremaining: 2.54s\n",
      "500:\tlearn: 0.0211616\ttotal: 2.15s\tremaining: 2.14s\n",
      "600:\tlearn: 0.0167282\ttotal: 2.5s\tremaining: 1.66s\n",
      "700:\tlearn: 0.0135363\ttotal: 2.9s\tremaining: 1.24s\n",
      "800:\tlearn: 0.0114164\ttotal: 3.25s\tremaining: 807ms\n",
      "900:\tlearn: 0.0099901\ttotal: 3.8s\tremaining: 417ms\n",
      "999:\tlearn: 0.0092753\ttotal: 4.25s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:34:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5768994\ttotal: 7.39ms\tremaining: 7.38s\n",
      "100:\tlearn: 0.1145030\ttotal: 371ms\tremaining: 3.3s\n",
      "200:\tlearn: 0.0714900\ttotal: 728ms\tremaining: 2.89s\n",
      "300:\tlearn: 0.0461566\ttotal: 1.09s\tremaining: 2.52s\n",
      "400:\tlearn: 0.0335462\ttotal: 1.43s\tremaining: 2.14s\n",
      "500:\tlearn: 0.0247397\ttotal: 1.82s\tremaining: 1.81s\n",
      "600:\tlearn: 0.0188524\ttotal: 2.24s\tremaining: 1.49s\n",
      "700:\tlearn: 0.0156000\ttotal: 2.64s\tremaining: 1.13s\n",
      "800:\tlearn: 0.0132015\ttotal: 3.04s\tremaining: 756ms\n",
      "900:\tlearn: 0.0117447\ttotal: 3.46s\tremaining: 380ms\n",
      "999:\tlearn: 0.0107278\ttotal: 3.87s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chapp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:34:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5719751\ttotal: 4.77ms\tremaining: 4.76s\n",
      "100:\tlearn: 0.0996137\ttotal: 462ms\tremaining: 4.11s\n",
      "200:\tlearn: 0.0573304\ttotal: 934ms\tremaining: 3.71s\n",
      "300:\tlearn: 0.0358949\ttotal: 1.39s\tremaining: 3.23s\n",
      "400:\tlearn: 0.0249307\ttotal: 1.84s\tremaining: 2.75s\n",
      "500:\tlearn: 0.0181705\ttotal: 2.34s\tremaining: 2.33s\n",
      "600:\tlearn: 0.0142450\ttotal: 2.82s\tremaining: 1.87s\n",
      "700:\tlearn: 0.0114224\ttotal: 3.29s\tremaining: 1.41s\n",
      "800:\tlearn: 0.0096208\ttotal: 3.69s\tremaining: 918ms\n",
      "900:\tlearn: 0.0084883\ttotal: 4.11s\tremaining: 451ms\n",
      "999:\tlearn: 0.0078242\ttotal: 4.54s\tremaining: 0us\n",
      "Random Forest Scores: [0.9494949494949495, 0.9324324324324325, 0.9494949494949495, 0.9459459459459459, 0.9169435215946844]\n",
      "XGBoost Scores: [0.9337748344370861, 0.9220338983050848, 0.9292929292929293, 0.9395973154362416, 0.9042904290429042]\n",
      "CatBoost Scores: [0.9431438127090301, 0.9403973509933775, 0.9504950495049505, 0.9530201342281879, 0.9139072847682119]\n",
      "Friedman Test Statistic: 7.6000000000000085\n",
      "P-value: 0.0223707718561655\n",
      "Random Forest: Average Rank = 1.60\n",
      "XGBoost: Average Rank = 3.00\n",
      "CatBoost: Average Rank = 1.40\n",
      "\n",
      "Model Rankings:\n",
      "1. CatBoost (Average Rank: 1.40)\n",
      "2. Random Forest (Average Rank: 1.60)\n",
      "3. XGBoost (Average Rank: 3.00)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import friedmanchisquare, rankdata\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    'CatBoost': CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=6, verbose=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Initialize K-Fold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize a dictionary to store scores\n",
    "model_scores = {model_name: [] for model_name in models.keys()}\n",
    "\n",
    "# Perform K-Fold Cross-Validation\n",
    "for train_idx, test_idx in kfold.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        score = f1_score(y_test, y_pred)  # You can use other metrics like F1-score\n",
    "        model_scores[model_name].append(score)\n",
    "\n",
    "# Print scores\n",
    "for model_name, scores in model_scores.items():\n",
    "    print(f\"{model_name} Scores: {scores}\")\n",
    "\n",
    "\n",
    "# Convert model scores to a matrix\n",
    "scores_matrix = np.array([model_scores[model_name] for model_name in models.keys()])\n",
    "\n",
    "# Perform Friedman Test\n",
    "stat, p = friedmanchisquare(*scores_matrix)\n",
    "print(\"Friedman Test Statistic:\", stat)\n",
    "print(\"P-value:\", p)\n",
    "\n",
    "# Rank models for each fold\n",
    "ranks = np.array([rankdata(-fold_scores) for fold_scores in scores_matrix.T])\n",
    "avg_ranks = ranks.mean(axis=0)\n",
    "\n",
    "# Print model rankings\n",
    "model_names = list(models.keys())\n",
    "for model, rank in zip(model_names, avg_ranks):\n",
    "    print(f\"{model}: Average Rank = {rank:.2f}\")\n",
    "\n",
    "# Sort and display rankings\n",
    "sorted_models = sorted(zip(model_names, avg_ranks), key=lambda x: x[1])\n",
    "print(\"\\nModel Rankings:\")\n",
    "for i, (model, rank) in enumerate(sorted_models, 1):\n",
    "    print(f\"{i}. {model} (Average Rank: {rank:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750e84f6-8151-4dcc-ad57-4c95983bf336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6668136-a859-4694-813b-57074b5f99df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc38f97-afcd-4e99-acfe-347de80ae660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1e2a4c0-f2fe-45b8-be0e-ca42ef94c662",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699c9671-f135-4f90-866e-f953295eb0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Stacking': StackingClassifier(\n",
    "    estimators=[('rf', rf), ('xgb', xgb), ('catboost', catboost)],  # Base models\n",
    "    final_estimator=RandomForestClassifier(n_estimators=100, random_state=42)),  # Meta learner\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier( eval_metric='logloss', random_state=42),\n",
    "    'CatBoost': CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=6, verbose=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Initialize K-Fold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize a dictionary to store scores\n",
    "model_scores = {model_name: [] for model_name in models.keys()}\n",
    "\n",
    "# Perform K-Fold Cross-Validation\n",
    "for train_idx, test_idx in kfold.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        score = f1_score(y_test, y_pred)  # You can use other metrics like F1-score\n",
    "        model_scores[model_name].append(score)\n",
    "\n",
    "# Print scores\n",
    "for model_name, scores in model_scores.items():\n",
    "    print(f\"{model_name} Scores: {scores}\")\n",
    "\n",
    "\n",
    "# Convert model scores to a matrix\n",
    "scores_matrix = np.array([model_scores[model_name] for model_name in models.keys()])\n",
    "\n",
    "# Perform Friedman Test\n",
    "stat, p = friedmanchisquare(*scores_matrix)\n",
    "print(\"Friedman Test Statistic:\", stat)\n",
    "print(\"P-value:\", p)\n",
    "\n",
    "# Rank models for each fold\n",
    "ranks = np.array([rankdata(-fold_scores) for fold_scores in scores_matrix.T])\n",
    "avg_ranks = ranks.mean(axis=0)\n",
    "\n",
    "# Print model rankings\n",
    "model_names = list(models.keys())\n",
    "for model, rank in zip(model_names, avg_ranks):\n",
    "    print(f\"{model}: Average Rank = {rank:.2f}\")\n",
    "\n",
    "# Sort and display rankings\n",
    "sorted_models = sorted(zip(model_names, avg_ranks), key=lambda x: x[1])\n",
    "print(\"\\nModel Rankings:\")\n",
    "for i, (model, rank) in enumerate(sorted_models, 1):\n",
    "    print(f\"{i}. {model} (Average Rank: {rank:.2f})\")\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa5393e-7d12-4120-ac44-7b27f189432c",
   "metadata": {},
   "source": [
    "## Friedman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ef4daa-0164-4d37-b5cd-f51d96e2a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier( eval_metric='logloss', random_state=42),\n",
    "    'CatBoost': CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=6, verbose=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Initialize K-Fold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize a dictionary to store scores\n",
    "model_scores = {model_name: [] for model_name in models.keys()}\n",
    "\n",
    "# Perform K-Fold Cross-Validation\n",
    "for train_idx, test_idx in kfold.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        score = f1_score(y_test, y_pred)  # You can use other metrics like F1-score\n",
    "        model_scores[model_name].append(score)\n",
    "\n",
    "# Print scores\n",
    "for model_name, scores in model_scores.items():\n",
    "    print(f\"{model_name} Scores: {scores}\")\n",
    "\n",
    "\n",
    "# Convert model scores to a matrix\n",
    "scores_matrix = np.array([model_scores[model_name] for model_name in models.keys()])\n",
    "\n",
    "# Perform Friedman Test\n",
    "stat, p = friedmanchisquare(*scores_matrix)\n",
    "print(\"Friedman Test Statistic:\", stat)\n",
    "print(\"P-value:\", p)\n",
    "\n",
    "# Rank models for each fold\n",
    "ranks = np.array([rankdata(-fold_scores) for fold_scores in scores_matrix.T])\n",
    "avg_ranks = ranks.mean(axis=0)\n",
    "\n",
    "# Print model rankings\n",
    "model_names = list(models.keys())\n",
    "for model, rank in zip(model_names, avg_ranks):\n",
    "    print(f\"{model}: Average Rank = {rank:.2f}\")\n",
    "\n",
    "# Sort and display rankings\n",
    "sorted_models = sorted(zip(model_names, avg_ranks), key=lambda x: x[1])\n",
    "print(\"\\nModel Rankings:\")\n",
    "for i, (model, rank) in enumerate(sorted_models, 1):\n",
    "    print(f\"{i}. {model} (Average Rank: {rank:.2f})\")\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
