{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29df649a-3846-4766-ab9e-12c3322d246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import resample\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import friedmanchisquare, rankdata\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb5fe16-8663-45c2-b0b2-fe91e18270dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data = pd.read_csv(\"alzheimers_disease_data.csv\")\n",
    "data.shape\n",
    "data.drop(['PatientID', 'DoctorInCharge'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "908d464c-6cee-4183-aa26-8851e28a6229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class Distribution:\n",
      " Diagnosis\n",
      "0    64.634714\n",
      "1    35.365286\n",
      "Name: proportion, dtype: float64\n",
      "Balanced Class Distribution:\n",
      " Diagnosis\n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_counts = data.iloc[:, -1].value_counts(normalize=True) * 100\n",
    "print(\"Original Class Distribution:\\n\", class_counts)\n",
    "\n",
    "# Splitting features and target variable\n",
    "X = data.iloc[:, :-1]  # Features\n",
    "y = data.iloc[:, -1]   # Target\n",
    "\n",
    "# Separate majority and minority classes\n",
    "majority_class = data[y == 0]  # Non-Alzheimer's (64.6%)\n",
    "minority_class = data[y == 1]  # Alzheimer's (35.4%)\n",
    "\n",
    "# Undersample the majority class to match the minority class size\n",
    "majority_downsampled = resample(majority_class, \n",
    "                                replace=False,  # Without replacement\n",
    "                                n_samples=len(minority_class),  # Match minority class size\n",
    "                                random_state=42)\n",
    "\n",
    "# Combine the downsampled majority class with the original minority class\n",
    "balanced_data = pd.concat([majority_downsampled, minority_class])\n",
    "\n",
    "# Shuffle the dataset\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check new class distribution\n",
    "new_class_counts = balanced_data.iloc[:, -1].value_counts(normalize=True) * 100\n",
    "print(\"Balanced Class Distribution:\\n\", new_class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeea8167-2750-4898-b910-4a0923c82665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Dataset After One-Hot Encoding:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholConsumption</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>DietQuality</th>\n",
       "      <th>SleepQuality</th>\n",
       "      <th>FamilyHistoryAlzheimers</th>\n",
       "      <th>CardiovascularDisease</th>\n",
       "      <th>...</th>\n",
       "      <th>Forgetfulness</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Ethnicity_0</th>\n",
       "      <th>Ethnicity_1</th>\n",
       "      <th>Ethnicity_2</th>\n",
       "      <th>Ethnicity_3</th>\n",
       "      <th>EducationLevel_0</th>\n",
       "      <th>EducationLevel_1</th>\n",
       "      <th>EducationLevel_2</th>\n",
       "      <th>EducationLevel_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>16.834968</td>\n",
       "      <td>0</td>\n",
       "      <td>19.053565</td>\n",
       "      <td>4.352272</td>\n",
       "      <td>3.432055</td>\n",
       "      <td>7.361459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>35.353244</td>\n",
       "      <td>1</td>\n",
       "      <td>0.768943</td>\n",
       "      <td>8.883326</td>\n",
       "      <td>4.085773</td>\n",
       "      <td>7.450835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>32.726550</td>\n",
       "      <td>0</td>\n",
       "      <td>16.971929</td>\n",
       "      <td>8.569751</td>\n",
       "      <td>8.744619</td>\n",
       "      <td>9.227229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>38.668960</td>\n",
       "      <td>1</td>\n",
       "      <td>6.669039</td>\n",
       "      <td>7.328895</td>\n",
       "      <td>7.973275</td>\n",
       "      <td>9.966551</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>30.646711</td>\n",
       "      <td>0</td>\n",
       "      <td>4.452856</td>\n",
       "      <td>0.768016</td>\n",
       "      <td>4.978013</td>\n",
       "      <td>7.715735</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender        BMI  Smoking  AlcoholConsumption  PhysicalActivity  \\\n",
       "0   80       1  16.834968        0           19.053565          4.352272   \n",
       "1   88       1  35.353244        1            0.768943          8.883326   \n",
       "2   63       0  32.726550        0           16.971929          8.569751   \n",
       "3   75       1  38.668960        1            6.669039          7.328895   \n",
       "4   72       0  30.646711        0            4.452856          0.768016   \n",
       "\n",
       "   DietQuality  SleepQuality  FamilyHistoryAlzheimers  CardiovascularDisease  \\\n",
       "0     3.432055      7.361459                        0                      0   \n",
       "1     4.085773      7.450835                        0                      0   \n",
       "2     8.744619      9.227229                        0                      0   \n",
       "3     7.973275      9.966551                        0                      0   \n",
       "4     4.978013      7.715735                        0                      1   \n",
       "\n",
       "   ...  Forgetfulness  Diagnosis  Ethnicity_0  Ethnicity_1  Ethnicity_2  \\\n",
       "0  ...              0          0          0.0          1.0          0.0   \n",
       "1  ...              1          1          1.0          0.0          0.0   \n",
       "2  ...              0          1          0.0          0.0          1.0   \n",
       "3  ...              1          0          0.0          0.0          0.0   \n",
       "4  ...              0          0          0.0          1.0          0.0   \n",
       "\n",
       "   Ethnicity_3  EducationLevel_0  EducationLevel_1  EducationLevel_2  \\\n",
       "0          0.0               0.0               1.0               0.0   \n",
       "1          0.0               0.0               1.0               0.0   \n",
       "2          0.0               0.0               1.0               0.0   \n",
       "3          1.0               0.0               0.0               1.0   \n",
       "4          0.0               0.0               0.0               1.0   \n",
       "\n",
       "   EducationLevel_3  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Select the nominal categorical features\n",
    "nominal_features = ['Ethnicity', 'EducationLevel']\n",
    "\n",
    "# Step 2: Initialize One-Hot Encoder without dropping any category\n",
    "ohe = OneHotEncoder(drop=None, sparse_output=False)  # Keep all categories\n",
    "\n",
    "# Step 3: Fit and transform the categorical features\n",
    "encoded_features = ohe.fit_transform(balanced_data[nominal_features])\n",
    "\n",
    "# Step 4: Convert the encoded features into a DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=ohe.get_feature_names_out(nominal_features))\n",
    "\n",
    "# Step 5: Drop the original categorical columns and merge encoded features\n",
    "data = balanced_data.drop(columns=nominal_features).reset_index(drop=True)  # Drop original categorical columns\n",
    "data = pd.concat([data, encoded_df], axis=1)  # Merge encoded data\n",
    "\n",
    "# Step 6: Verify the transformed data\n",
    "print(\"Updated Dataset After One-Hot Encoding:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d079d13a-4e32-4d0d-bd8a-8c9949c5fdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['FunctionalAssessment', 'ADL', 'MemoryComplaints', 'MMSE', 'BehavioralProblems', 'SleepQuality', 'CholesterolHDL', 'CholesterolLDL', 'BMI', 'CholesterolTriglycerides', 'Age', 'PhysicalActivity', 'DietQuality', 'DiastolicBP', 'Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3ebab28d-d1fb-487e-90e0-414bf3de4d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_selected_features = ['FunctionalAssessment', 'ADL', 'MemoryComplaints', 'MMSE', 'BehavioralProblems']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a92ccdb9-72e2-4d99-9fb7-5a5393da0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct filtering for Male and Female\n",
    "male = data[data['Gender'] == 0]  # Assuming 0 represents Male\n",
    "female = data[data['Gender'] == 1]  # Assuming 1 represents Female\n",
    "\n",
    "X = data[selected_features]  \n",
    "X_top = data[top_selected_features]  \n",
    "y = data['Diagnosis']\n",
    "\n",
    "\n",
    "# Split features and target for Males\n",
    "X_male = male[selected_features]  \n",
    "y_male = male['Diagnosis']\n",
    "\n",
    "# Split features and target for Females\n",
    "X_female = female[selected_features]  \n",
    "y_female = female['Diagnosis']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b355bf1d-bc7a-4764-98b4-b533dfc0125e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(763, 39)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b4c4aa8-21f8-40d8-8029-ab540bce1bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(757, 39)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f98d4a20-c2b6-41f9-bf30-be3bb950cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_top, X_test_top, y_train_top, y_test_top = train_test_split(X_top, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler_top = StandardScaler()\n",
    "\n",
    "# Fit on training data and transform both train and test separately\n",
    "X_train_scaled_top = scaler.fit_transform(X_train_top)  \n",
    "X_test_scaled_top = scaler.transform(X_test_top)  \n",
    "\n",
    "\n",
    "# Split the data into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data and transform both train and test separately\n",
    "X_train_scaled = scaler.fit_transform(X_train)  \n",
    "X_test_scaled = scaler.transform(X_test)  \n",
    "\n",
    "# Split Male Data\n",
    "X_male_train, X_male_test, y_male_train, y_male_test = train_test_split(\n",
    "    X_male, y_male, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Split Female Data\n",
    "X_female_train, X_female_test, y_female_train, y_female_test = train_test_split(\n",
    "    X_female, y_female, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler_male = StandardScaler()\n",
    "scaler_female = StandardScaler()\n",
    "\n",
    "# Scale Male Data\n",
    "X_male_train_scaled = scaler_male.fit_transform(X_male_train)\n",
    "X_male_test_scaled = scaler_male.transform(X_male_test)\n",
    "\n",
    "# Scale Female Data\n",
    "X_female_train_scaled = scaler_female.fit_transform(X_female_train)\n",
    "X_female_test_scaled = scaler_female.transform(X_female_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9212fd-e16d-40cb-b989-009ed9873701",
   "metadata": {},
   "source": [
    "## Top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f80d79e-d4fd-47aa-b304-54a68e62f79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9407894736842105\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.929     0.954     0.941       151\n",
      "           1      0.953     0.928     0.940       153\n",
      "\n",
      "    accuracy                          0.941       304\n",
      "   macro avg      0.941     0.941     0.941       304\n",
      "weighted avg      0.941     0.941     0.941       304\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[144   7]\n",
      " [ 11 142]]\n"
     ]
    }
   ],
   "source": [
    "catboost = CatBoostClassifier(\n",
    "    border_count=128, \n",
    "    depth=4, \n",
    "    iterations=500, \n",
    "    l2_leaf_reg=3, \n",
    "    learning_rate=0.01, \n",
    "    loss_function='Logloss', \n",
    "    random_seed=42,  \n",
    "    verbose=0  \n",
    ")\n",
    "\n",
    "catboost.fit(X_train_scaled_top, y_train_top)\n",
    "\n",
    "catboost_y_pred = catboost.predict(X_test_scaled_top)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_top, catboost_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_top, catboost_y_pred, digits=3))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test_top, catboost_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e84358b-c56d-47f4-a3e9-56db7953b39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9407894736842105\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.929     0.954     0.941       151\n",
      "           1      0.953     0.928     0.940       153\n",
      "\n",
      "    accuracy                          0.941       304\n",
      "   macro avg      0.941     0.941     0.941       304\n",
      "weighted avg      0.941     0.941     0.941       304\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[144   7]\n",
      " [ 11 142]]\n"
     ]
    }
   ],
   "source": [
    "catboost = CatBoostClassifier(\n",
    "    border_count=128, \n",
    "    depth=4, \n",
    "    iterations=500, \n",
    "    l2_leaf_reg=3, \n",
    "    learning_rate=0.01, \n",
    "    loss_function='Logloss', \n",
    "    random_seed=42,  \n",
    "    verbose=0  \n",
    ")\n",
    "\n",
    "catboost.fit(X_train_scaled, y_train)\n",
    "\n",
    "catboost_y_pred = catboost.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, catboost_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, catboost_y_pred, digits=3))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, catboost_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04df6187-aec1-4d6c-89f2-810cc73da726",
   "metadata": {},
   "source": [
    "## man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d100bb78-52b5-4a9e-988e-91411d3cfd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9084967320261438\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.857     0.938     0.896        64\n",
      "           1      0.952     0.888     0.919        89\n",
      "\n",
      "    accuracy                          0.908       153\n",
      "   macro avg      0.904     0.913     0.907       153\n",
      "weighted avg      0.912     0.908     0.909       153\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[60  4]\n",
      " [10 79]]\n"
     ]
    }
   ],
   "source": [
    "catboost = CatBoostClassifier(\n",
    "    border_count=128, \n",
    "    depth=4, \n",
    "    iterations=500, \n",
    "    l2_leaf_reg=3, \n",
    "    learning_rate=0.01, \n",
    "    loss_function='Logloss', \n",
    "    random_seed=42,  \n",
    "    verbose=0  \n",
    ")\n",
    "\n",
    "catboost.fit(X_male_train_scaled, y_male_train)\n",
    "\n",
    "catboost_y_pred = catboost.predict(X_male_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_male_test, catboost_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_male_test, catboost_y_pred, digits=3))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_male_test, catboost_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef6412fb-4bab-4f5e-af21-1b80a0e6a649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9473684210526315\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.937     0.961     0.949        77\n",
      "           1      0.959     0.933     0.946        75\n",
      "\n",
      "    accuracy                          0.947       152\n",
      "   macro avg      0.948     0.947     0.947       152\n",
      "weighted avg      0.948     0.947     0.947       152\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[74  3]\n",
      " [ 5 70]]\n"
     ]
    }
   ],
   "source": [
    "catboost = CatBoostClassifier(\n",
    "    border_count=128, \n",
    "    depth=4, \n",
    "    iterations=500, \n",
    "    l2_leaf_reg=3, \n",
    "    learning_rate=0.01, \n",
    "    loss_function='Logloss', \n",
    "    random_seed=42,  \n",
    "    verbose=0  \n",
    ")\n",
    "\n",
    "catboost.fit(X_female_train_scaled, y_female_train)\n",
    "\n",
    "catboost_y_pred = catboost.predict(X_female_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_female_test, catboost_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_female_test, catboost_y_pred, digits=3))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_female_test, catboost_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092c3330-5134-45ee-a464-0657b13b857f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
